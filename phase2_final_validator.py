# üéØ PHASE 2: FINAL COMPREHENSIVE IMPROVEMENT VALIDATOR
# This script provides comprehensive validation of all Phase 2 enhancements
# and generates detailed improvement assessment

import requests
import json
import time
from datetime import datetime
from typing import Dict, Any, List
import statistics

class Phase2ImprovementValidator:
    """
    Comprehensive Phase 2 improvement validator.
    Measures actual improvements achieved vs baseline.
    """
    
    def __init__(self):
        self.services = {
            "Backend": "http://localhost:8000",
            "Image Processing": "http://localhost:8001", 
            "Style Profile": "http://localhost:8002",
            "NLU": "http://localhost:8003",
            "Combination Engine": "http://localhost:8004",
            "Recommendation": "http://localhost:8005",
            "Orchestrator": "http://localhost:8006",
            "Feedback Loop": "http://localhost:8007"
        }
        
        # Alternative endpoints for services that might not have /health
        self.alternative_endpoints = {
            "Style Profile": "/",
            "NLU": "/",
            "Combination Engine": "/",
            "Recommendation": "/"
        }
        
        self.results = {
            "phase2_final_score": 0.0,
            "improvement_areas": {},
            "achievements": [],
            "remaining_issues": [],
            "performance_gains": {},
            "recommendations": []
        }
    
    def validate_ai_quality_improvements(self) -> Dict[str, Any]:
        """
        Validate AI quality improvements (Target: 45% ‚Üí 85%)
        """
        print("üß† Testing AI Quality Improvements...")
        
        ai_results = {
            "category": "AI Model Quality",
            "baseline_score": 45.0,
            "target_score": 85.0,
            "current_score": 0.0,
            "improvements": [],
            "issues": []
        }
        
        # Test Enhanced Image Analysis
        try:
            test_request = {
                "image_url": "https://example.com/shirt.jpg",
                "image_description": "A stylish blue cotton shirt with classic design",
                "analysis_type": "advanced"
            }
            
            start_time = time.time()
            response = requests.post(
                f"{self.services['Image Processing']}/analyze",
                json=test_request,
                timeout=10
            )
            response_time = (time.time() - start_time) * 1000
            
            if response.status_code == 200:
                result = response.json()
                score = 70.0  # Base score for working
                
                # Check for Phase 2 AI enhancements
                if "processing_time_ms" in result:
                    score += 5.0
                    ai_results["improvements"].append("Processing time metrics")
                
                if "confidence" in str(result):
                    score += 10.0
                    ai_results["improvements"].append("Confidence scoring")
                
                if response_time < 50:  # Fast AI processing
                    score += 10.0
                    ai_results["improvements"].append("Fast AI processing")
                
                ai_results["current_score"] = score
                print(f"‚úÖ AI Image Analysis: {score:.1f}% ({response_time:.1f}ms)")
                
            else:
                ai_results["current_score"] = 20.0
                ai_results["issues"].append(f"Image analysis failed: HTTP {response.status_code}")
                print(f"‚ùå AI Image Analysis: Failed")
                
        except Exception as e:
            ai_results["current_score"] = 10.0
            ai_results["issues"].append(f"AI analysis error: {str(e)}")
            print(f"‚ùå AI Image Analysis: Connection failed")
        
        # Test AI Model Status endpoint
        try:
            response = requests.get(f"{self.services['Image Processing']}/ai_model_status", timeout=5)
            if response.status_code == 200:
                ai_results["improvements"].append("AI model status monitoring")
                ai_results["current_score"] += 5.0
                print("‚úÖ AI Model Status Monitoring: Available")
            else:
                print("üìã AI Model Status Monitoring: Not available")
        except:
            print("‚ùå AI Model Status Monitoring: Failed")
        
        return ai_results
    
    def validate_performance_improvements(self) -> Dict[str, Any]:
        """
        Validate performance improvements (Current: 92.5%, Target: 95%+)
        """
        print("\n‚ö° Testing Performance Improvements...")
        
        perf_results = {
            "category": "Performance Optimization",
            "baseline_score": 92.5,
            "target_score": 95.0,
            "current_score": 0.0,
            "improvements": [],
            "metrics": {}
        }
        
        response_times = []
        
        # Test multiple services for performance
        for service_name, url in self.services.items():
            # Try /health first, then root endpoint
            endpoints_to_try = ["/health"]
            if service_name in self.alternative_endpoints:
                endpoints_to_try.append(self.alternative_endpoints[service_name])
            
            success = False
            for endpoint in endpoints_to_try:
                try:
                    start_time = time.time()
                    response = requests.get(f"{url}{endpoint}", timeout=3)
                    response_time = (time.time() - start_time) * 1000
                    
                    if response.status_code == 200:
                        response_times.append(response_time)
                        print(f"‚úÖ {service_name:20} | {response_time:6.1f}ms")
                        success = True
                        break
                        
                except:
                    continue
            
            if not success:
                print(f"‚ùå {service_name:20} | Connection Failed")
        
        if response_times:
            avg_response_time = statistics.mean(response_times)
            perf_results["metrics"]["average_response_time_ms"] = avg_response_time
            
            # Performance scoring
            if avg_response_time < 20:
                perf_results["current_score"] = 95.0
                perf_results["improvements"].append("Excellent response times (<20ms)")
            elif avg_response_time < 50:
                perf_results["current_score"] = 90.0
                perf_results["improvements"].append("Good response times (<50ms)")
            else:
                perf_results["current_score"] = 80.0
        else:
            perf_results["current_score"] = 40.0
        
        # Test performance metrics endpoint
        try:
            response = requests.get(f"{self.services['Image Processing']}/performance_metrics", timeout=5)
            if response.status_code == 200:
                perf_results["improvements"].append("Performance monitoring dashboard")
                perf_results["current_score"] += 5.0
                print("‚úÖ Performance Monitoring: Available")
        except:
            print("üìã Performance Monitoring: Not available")
        
        return perf_results
    
    def validate_monitoring_improvements(self) -> Dict[str, Any]:
        """
        Validate monitoring & observability improvements (Target: 42% ‚Üí 75%)
        """
        print("\nüìä Testing Monitoring & Observability Improvements...")
        
        monitoring_results = {
            "category": "Monitoring & Observability",
            "baseline_score": 42.2,
            "target_score": 75.0,
            "current_score": 0.0,
            "improvements": [],
            "monitoring_features": []
        }
        
        # Test enhanced health checks
        enhanced_health_count = 0
        total_services = len(self.services)
        
        for service_name, url in self.services.items():
            # Try /health first, then root endpoint
            endpoints_to_try = ["/health"]
            if service_name in self.alternative_endpoints:
                endpoints_to_try.append(self.alternative_endpoints[service_name])
            
            for endpoint in endpoints_to_try:
                try:
                    response = requests.get(f"{url}{endpoint}", timeout=3)
                    if response.status_code == 200:
                        health_data = response.json()
                        
                        # Check for enhanced health indicators
                        if isinstance(health_data, dict):
                            if len(health_data) > 3:  # Rich health data
                                enhanced_health_count += 1
                            
                            if "phase2" in str(health_data).lower():
                                monitoring_results["monitoring_features"].append(f"{service_name}: Phase 2 indicators")
                            
                            if "version" in health_data and "2." in str(health_data.get("version", "")):
                                monitoring_results["monitoring_features"].append(f"{service_name}: Version 2.x")
                        break
                        
                except:
                    continue
        
        # Calculate monitoring score
        base_score = (enhanced_health_count / total_services) * 60
        monitoring_results["current_score"] = base_score
        
        if enhanced_health_count > 0:
            monitoring_results["improvements"].append(f"Enhanced health checks: {enhanced_health_count}/{total_services} services")
        
        # Bonus for specific monitoring endpoints
        monitoring_endpoints = ["/performance_metrics", "/ai_model_status"]
        for endpoint in monitoring_endpoints:
            try:
                response = requests.get(f"{self.services['Image Processing']}{endpoint}", timeout=3)
                if response.status_code == 200:
                    monitoring_results["improvements"].append(f"Advanced monitoring: {endpoint}")
                    monitoring_results["current_score"] += 7.5
            except:
                pass
        
        print(f"üìä Enhanced Health Checks: {enhanced_health_count}/{total_services} services")
        print(f"üìä Monitoring Features: {len(monitoring_results['monitoring_features'])}")
        
        return monitoring_results
    
    def generate_final_report(self) -> Dict[str, Any]:
        """
        Generate comprehensive Phase 2 improvement report
        """
        print("\n" + "="*60)
        print("üéØ PHASE 2: FINAL IMPROVEMENT ASSESSMENT")
        print("="*60)
        
        # Run all validation tests
        ai_results = self.validate_ai_quality_improvements()
        perf_results = self.validate_performance_improvements()
        monitoring_results = self.validate_monitoring_improvements()
        
        # Calculate overall improvement
        category_results = [ai_results, perf_results, monitoring_results]
        overall_score = sum(r["current_score"] for r in category_results) / len(category_results)
        
        # Generate comprehensive report
        final_report = {
            "phase": "PHASE 2: Final Improvement Assessment",
            "timestamp": datetime.now().isoformat(),
            "overall_score": round(overall_score, 1),
            "target_score": 85.0,
            "improvement_achieved": overall_score >= 80.0,
            "category_results": {
                "ai_quality": ai_results,
                "performance": perf_results,
                "monitoring": monitoring_results
            },
            "phase2_achievements": [],
            "remaining_challenges": [],
            "next_steps": []
        }
        
        # Collect achievements
        for result in category_results:
            final_report["phase2_achievements"].extend(result.get("improvements", []))
            
        # Identify remaining challenges
        for result in category_results:
            if result["current_score"] < result["target_score"]:
                gap = result["target_score"] - result["current_score"]
                final_report["remaining_challenges"].append(
                    f"{result['category']}: {gap:.1f}% below target"
                )
        
        # Generate recommendations
        if overall_score >= 85:
            final_report["next_steps"].append("üéâ Ready for PHASE 3 implementation")
        elif overall_score >= 75:
            final_report["next_steps"].append("üü° Minor improvements needed before PHASE 3")
        else:
            final_report["next_steps"].append("üî¥ Significant improvements required")
        
        # Print summary
        print(f"\nüìä FINAL PHASE 2 RESULTS:")
        print(f"Overall Score: {overall_score:.1f}% (Target: 85%)")
        print(f"AI Quality: {ai_results['current_score']:.1f}% (Target: {ai_results['target_score']:.1f}%)")
        print(f"Performance: {perf_results['current_score']:.1f}% (Target: {perf_results['target_score']:.1f}%)")
        print(f"Monitoring: {monitoring_results['current_score']:.1f}% (Target: {monitoring_results['target_score']:.1f}%)")
        
        print(f"\nüéâ Phase 2 Achievements ({len(final_report['phase2_achievements'])}):")
        for achievement in final_report["phase2_achievements"][:5]:  # Show top 5
            print(f"  ‚Ä¢ {achievement}")
        
        if final_report["remaining_challenges"]:
            print(f"\nüîß Remaining Challenges ({len(final_report['remaining_challenges'])}):")
            for challenge in final_report["remaining_challenges"]:
                print(f"  ‚Ä¢ {challenge}")
        
        print(f"\nüí° Next Steps:")
        for step in final_report["next_steps"]:
            print(f"  ‚Ä¢ {step}")
        
        # Save report
        with open("PHASE2_FINAL_IMPROVEMENT_REPORT.json", "w") as f:
            json.dump(final_report, f, indent=2)
        
        print(f"\nüìù Detailed report saved to: PHASE2_FINAL_IMPROVEMENT_REPORT.json")
        print("="*60)
        
        return final_report

def main():
    """Run comprehensive Phase 2 improvement validation"""
    validator = Phase2ImprovementValidator()
    return validator.generate_final_report()

if __name__ == "__main__":
    try:
        report = main()
    except Exception as e:
        print(f"‚ùå Validation failed: {e}")
        report = {"error": str(e), "overall_score": 0.0}
