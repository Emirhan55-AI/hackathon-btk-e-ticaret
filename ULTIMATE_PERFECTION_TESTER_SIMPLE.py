#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ ULTIMATE PERFECTION TESTER - Basit SÃ¼rÃ¼m
================================================================================
Sistemin %100 mÃ¼kemmelliÄŸe ulaÅŸmasÄ± iÃ§in kapsamlÄ± test sÃ¼reci (sadece stdlib kullanarak)
"""

import requests
import time
import json
import subprocess
import os
import sys
import traceback
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import threading
import concurrent.futures

class UltimatePerfectionTesterSimple:
    """
    MÃ¼kemmellik test sistemi - sadece standart kÃ¼tÃ¼phaneler kullanarak
    """
    
    def __init__(self):
        self.start_time = datetime.now()
        self.test_results = []
        self.services = {
            'backend': 'http://localhost:8000',
            'image_processing': 'http://localhost:8001',
            'nlu': 'http://localhost:8002',
            'style_profile': 'http://localhost:8003',
            'combination_engine': 'http://localhost:8004',
            'recommendation': 'http://localhost:8005',
            'orchestrator': 'http://localhost:8006',
            'feedback': 'http://localhost:8007'
        }
        
        self.workspace_path = os.path.dirname(os.path.abspath(__file__))
        
        print("ğŸš€ ULTIMATE PERFECTION TESTER (Simple) Ä°NÄ°TÄ°ALÄ°ZE EDÄ°LDÄ°")
        print("=" * 80)
        print("ğŸ¯ Hedef: %100 Kusursuzluk")
        print(f"ğŸ”§ Mikroservisler: {len(self.services)}")
        print("=" * 80)
    
    def add_test_result(self, test_name: str, category: str, status: str, message: str, execution_time: float, details: dict = None):
        """Test sonucu ekle"""
        result = {
            'test_name': test_name,
            'category': category,
            'status': status,
            'message': message,
            'execution_time': execution_time,
            'details': details or {},
            'timestamp': datetime.now().isoformat()
        }
        self.test_results.append(result)
        
        status_emoji = {"PASS": "âœ…", "FAIL": "âŒ", "SKIP": "â­ï¸", "ERROR": "ğŸš¨"}
        print(f"{status_emoji.get(status, 'â“')} [{category}] {test_name}: {message}")
    
    def test_service_health(self, service_name: str, url: str) -> dict:
        """Servis saÄŸlÄ±k testi"""
        start_time = time.time()
        
        try:
            # FarklÄ± health endpoint'lerini dene
            health_endpoints = ['/', '/health', '/status', '/docs']
            
            for endpoint in health_endpoints:
                try:
                    response = requests.get(f"{url}{endpoint}", timeout=10)
                    response_time = time.time() - start_time
                    
                    if response.status_code == 200:
                        self.add_test_result(
                            f"Service Health - {service_name}",
                            "INTEGRATION_TESTS",
                            "PASS",
                            f"Servis saÄŸlÄ±klÄ± ({response.status_code}) - {response_time:.3f}s",
                            response_time,
                            {
                                "endpoint": endpoint,
                                "status_code": response.status_code,
                                "response_size": len(response.text)
                            }
                        )
                        return {"status": "healthy", "endpoint": endpoint, "response_time": response_time}
                except:
                    continue
            
            # HiÃ§bir endpoint Ã§alÄ±ÅŸmÄ±yor
            self.add_test_result(
                f"Service Health - {service_name}",
                "INTEGRATION_TESTS",
                "FAIL",
                "HiÃ§bir health endpoint eriÅŸilebilir deÄŸil",
                time.time() - start_time,
                {"attempted_endpoints": health_endpoints}
            )
            return {"status": "unhealthy"}
            
        except Exception as e:
            self.add_test_result(
                f"Service Health - {service_name}",
                "INTEGRATION_TESTS",
                "ERROR",
                f"BaÄŸlantÄ± hatasÄ±: {str(e)}",
                time.time() - start_time,
                {}
            )
            return {"status": "error", "error": str(e)}
    
    def test_api_endpoints(self, service_name: str, url: str):
        """API endpoint'lerini test et"""
        
        # Her servis iÃ§in ana endpoint'leri tanÄ±mla
        service_endpoints = {
            'backend': [
                {'path': '/health', 'method': 'GET'},
                {'path': '/api/v1/products/', 'method': 'GET'},
                {'path': '/docs', 'method': 'GET'}
            ],
            'image_processing': [
                {'path': '/', 'method': 'GET'},
                {'path': '/analyze', 'method': 'POST'}
            ],
            'nlu': [
                {'path': '/', 'method': 'GET'}, 
                {'path': '/parse_request', 'method': 'POST'}
            ],
            'style_profile': [
                {'path': '/', 'method': 'GET'},
                {'path': '/create_profile', 'method': 'POST'}
            ],
            'combination_engine': [
                {'path': '/', 'method': 'GET'},
                {'path': '/generate_combinations', 'method': 'POST'}
            ],
            'recommendation': [
                {'path': '/', 'method': 'GET'},
                {'path': '/get_recommendations', 'method': 'POST'}
            ],
            'orchestrator': [
                {'path': '/', 'method': 'GET'},
                {'path': '/orchestrate_workflow', 'method': 'POST'}
            ],
            'feedback': [
                {'path': '/', 'method': 'GET'},
                {'path': '/process_feedback', 'method': 'POST'}
            ]
        }
        
        endpoints = service_endpoints.get(service_name, [{'path': '/', 'method': 'GET'}])
        
        for endpoint_info in endpoints:
            start_time = time.time()
            path = endpoint_info['path']
            method = endpoint_info['method']
            
            try:
                if method == 'GET':
                    response = requests.get(f"{url}{path}", timeout=15)
                    response_time = time.time() - start_time
                    
                    if response.status_code in [200, 404]:  # 404 da kabul edilebilir
                        status = "PASS" if response.status_code == 200 else "SKIP"
                        message = f"GET {path}: {response.status_code} - {response_time:.3f}s"
                    else:
                        status = "FAIL"
                        message = f"GET {path}: Beklenmeyen status {response.status_code}"
                        
                elif method == 'POST':
                    # Mock data ile POST test et
                    test_data = self.get_mock_data_for_endpoint(service_name, path)
                    
                    response = requests.post(f"{url}{path}", json=test_data, timeout=15)
                    response_time = time.time() - start_time
                    
                    if response.status_code in [200, 201, 422, 404]:  # 422 validation error kabul edilebilir
                        status = "PASS" if response.status_code in [200, 201] else "SKIP"
                        message = f"POST {path}: {response.status_code} - {response_time:.3f}s"
                    else:
                        status = "FAIL"
                        message = f"POST {path}: Beklenmeyen status {response.status_code}"
                
                self.add_test_result(
                    f"API Test - {service_name}{path}",
                    "INTEGRATION_TESTS",
                    status,
                    message,
                    response_time,
                    {
                        "method": method,
                        "status_code": response.status_code,
                        "response_size": len(response.text)
                    }
                )
                
                # KÄ±sa bekleme
                time.sleep(0.1)
                    
            except Exception as e:
                self.add_test_result(
                    f"API Test - {service_name}{path}",
                    "INTEGRATION_TESTS",
                    "ERROR",
                    f"{method} {path}: {str(e)}",
                    time.time() - start_time,
                    {"method": method}
                )
    
    def get_mock_data_for_endpoint(self, service_name: str, path: str) -> dict:
        """Endpoint iÃ§in mock test verisi Ã¼ret"""
        mock_data = {
            'image_processing': {
                '/analyze': {
                    'image_description': 'Test kÄ±yafet',
                    'analysis_type': 'clothing_detection'
                }
            },
            'nlu': {
                '/parse_request': {
                    'text': 'Mavi bir gÃ¶mlek istiyorum',
                    'language': 'tr'
                }
            },
            'style_profile': {
                '/create_profile': {
                    'user_preferences': {'style': 'casual'},
                    'wardrobe_analysis': {}
                }
            },
            'combination_engine': {
                '/generate_combinations': {
                    'style_profile': {},
                    'occasion': 'casual'
                }
            },
            'recommendation': {
                '/get_recommendations': {
                    'user_profile': {},
                    'combinations': []
                }
            },
            'orchestrator': {
                '/orchestrate_workflow': {
                    'workflow_type': 'recommendation',
                    'user_input': 'Test isteÄŸi'
                }
            },
            'feedback': {
                '/process_feedback': {
                    'recommendations': [],
                    'user_rating': 5
                }
            }
        }
        
        return mock_data.get(service_name, {}).get(path, {})
    
    def test_service_performance(self, service_name: str, url: str):
        """Servis performans testi"""
        start_time = time.time()
        
        try:
            # SÄ±ralÄ± istekler gÃ¶nder (threading yerine)
            response_times = []
            success_count = 0
            
            for i in range(5):  # 5 istek gÃ¶nder
                try:
                    request_start = time.time()
                    response = requests.get(f"{url}/", timeout=10)
                    response_time = time.time() - request_start
                    
                    response_times.append(response_time)
                    if response.status_code == 200:
                        success_count += 1
                        
                except:
                    pass
                
                time.sleep(0.2)  # KÄ±sa bekleme
            
            if response_times:
                avg_response_time = sum(response_times) / len(response_times)
                max_response_time = max(response_times)
                
                # Performance kriterleri
                if avg_response_time < 2.0 and success_count >= 4:
                    status = "PASS"
                    message = f"Ä°yi performans: Ort:{avg_response_time:.3f}s, BaÅŸarÄ±:{success_count}/5"
                elif avg_response_time < 5.0 and success_count >= 2:
                    status = "SKIP" 
                    message = f"Orta performans: Ort:{avg_response_time:.3f}s, BaÅŸarÄ±:{success_count}/5"
                else:
                    status = "FAIL"
                    message = f"DÃ¼ÅŸÃ¼k performans: Ort:{avg_response_time:.3f}s, BaÅŸarÄ±:{success_count}/5"
                
                self.add_test_result(
                    f"Performance Test - {service_name}",
                    "PERFORMANCE_TESTS",
                    status,
                    message,
                    time.time() - start_time,
                    {
                        "avg_response_time": avg_response_time,
                        "max_response_time": max_response_time,
                        "success_rate": success_count / 5,
                        "total_requests": 5
                    }
                )
            else:
                self.add_test_result(
                    f"Performance Test - {service_name}",
                    "PERFORMANCE_TESTS",
                    "FAIL",
                    "HiÃ§bir istek baÅŸarÄ±lÄ± olmadÄ±",
                    time.time() - start_time,
                    {}
                )
                
        except Exception as e:
            self.add_test_result(
                f"Performance Test - {service_name}",
                "PERFORMANCE_TESTS",
                "ERROR",
                f"Performance test hatasÄ±: {str(e)}",
                time.time() - start_time,
                {}
            )
    
    def test_end_to_end_workflow(self):
        """UÃ§tan uca workflow testi"""
        start_time = time.time()
        
        try:
            print("\nğŸ”„ End-to-End Workflow Test baÅŸlatÄ±lÄ±yor...")
            
            # Demo script'i Ã§alÄ±ÅŸtÄ±rarak e2e test yap
            demo_result = subprocess.run(
                [sys.executable, "ucan_uca_demo.py"],
                input="",  # Enter tuÅŸuna basma simÃ¼lasyonu
                text=True,
                capture_output=True,
                timeout=120,  # 2 dakika timeout
                cwd=self.workspace_path
            )
            
            execution_time = time.time() - start_time
            
            if demo_result.returncode == 0:
                # BaÅŸarÄ±lÄ± Ã§Ä±ktÄ±yÄ± analiz et
                output = demo_result.stdout + demo_result.stderr
                
                if "Demo baÅŸarÄ±yla tamamlandÄ±" in output:
                    status = "PASS"
                    message = f"E2E workflow baÅŸarÄ±lÄ± - {execution_time:.3f}s"
                elif "Workflow baÅŸarÄ± oranÄ±: %98" in output or "baÅŸarÄ± oranÄ±: %9" in output:
                    status = "PASS"
                    message = f"E2E workflow yÃ¼ksek baÅŸarÄ± oranÄ±yla tamamlandÄ± - {execution_time:.3f}s"
                else:
                    status = "SKIP"
                    message = f"E2E workflow kÄ±smen baÅŸarÄ±lÄ± - {execution_time:.3f}s"
                
                self.add_test_result(
                    "End-to-End Workflow Test",
                    "END_TO_END_TESTS",
                    status,
                    message,
                    execution_time,
                    {
                        "return_code": demo_result.returncode,
                        "output_length": len(output),
                        "contains_success": "baÅŸarÄ±yla tamamlandÄ±" in output
                    }
                )
            else:
                self.add_test_result(
                    "End-to-End Workflow Test",
                    "END_TO_END_TESTS",
                    "FAIL",
                    f"E2E workflow baÅŸarÄ±sÄ±z (exit code: {demo_result.returncode})",
                    execution_time,
                    {
                        "return_code": demo_result.returncode,
                        "stdout": demo_result.stdout[:500],
                        "stderr": demo_result.stderr[:500]
                    }
                )
                
        except subprocess.TimeoutExpired:
            self.add_test_result(
                "End-to-End Workflow Test",
                "END_TO_END_TESTS",
                "FAIL",
                "E2E workflow timeout (120s)",
                time.time() - start_time,
                {"error": "timeout"}
            )
        except Exception as e:
            self.add_test_result(
                "End-to-End Workflow Test", 
                "END_TO_END_TESTS",
                "ERROR",
                f"E2E workflow hatasÄ±: {str(e)}",
                time.time() - start_time,
                {}
            )
    
    def test_ai_model_outputs(self):
        """AI model Ã§Ä±ktÄ±larÄ±nÄ± doÄŸrula"""
        
        # Her AI servisinin mantÄ±klÄ± Ã§Ä±ktÄ± Ã¼retip Ã¼retmediÄŸini test et
        ai_services = ['image_processing', 'nlu', 'style_profile', 'combination_engine', 'recommendation']
        
        for service_name in ai_services:
            start_time = time.time()
            
            try:
                test_data = self.get_ai_validation_data(service_name)
                endpoint = self.get_ai_endpoint(service_name)
                
                response = requests.post(
                    f"{self.services[service_name]}{endpoint}",
                    json=test_data,
                    timeout=15
                )
                
                response_time = time.time() - start_time
                
                if response.status_code == 200:
                    try:
                        response_data = response.json()
                        
                        # AI Ã§Ä±ktÄ±sÄ±nÄ± doÄŸrula
                        validation_result = self.validate_ai_output(service_name, response_data)
                        
                        if validation_result['valid']:
                            status = "PASS"
                            message = f"AI Ã§Ä±ktÄ±sÄ± geÃ§erli - {service_name}"
                        else:
                            status = "FAIL"
                            message = f"AI Ã§Ä±ktÄ±sÄ± geÃ§ersiz - {service_name}: {validation_result['reason']}"
                        
                        self.add_test_result(
                            f"AI Validation - {service_name}",
                            "AI_VALIDATION_TESTS",
                            status,
                            message,
                            response_time,
                            {
                                "service": service_name,
                                "validation": validation_result,
                                "response_keys": list(response_data.keys()) if isinstance(response_data, dict) else str(type(response_data))
                            }
                        )
                    except json.JSONDecodeError:
                        self.add_test_result(
                            f"AI Validation - {service_name}",
                            "AI_VALIDATION_TESTS",
                            "FAIL",
                            f"AI servisi geÃ§ersiz JSON dÃ¶ndÃ¼rdÃ¼",
                            response_time,
                            {"service": service_name, "response_text": response.text[:200]}
                        )
                else:
                    self.add_test_result(
                        f"AI Validation - {service_name}",
                        "AI_VALIDATION_TESTS",
                        "FAIL",
                        f"AI servisi yanÄ±t vermiyor: {response.status_code}",
                        response_time,
                        {"service": service_name, "status_code": response.status_code}
                    )
                    
            except Exception as e:
                self.add_test_result(
                    f"AI Validation - {service_name}",
                    "AI_VALIDATION_TESTS",
                    "ERROR",
                    f"AI validation hatasÄ±: {str(e)}",
                    time.time() - start_time,
                    {"service": service_name}
                )
    
    def get_ai_validation_data(self, service_name: str) -> dict:
        """AI servisi iÃ§in test verisi"""
        data = {
            'image_processing': {
                'image_description': 'Mavi bir gÃ¶mlek ve siyah pantolon',
                'analysis_type': 'clothing_detection'
            },
            'nlu': {
                'text': 'BugÃ¼n hava gÃ¼zel, spor iÃ§in ayakkabÄ± arÄ±yorum',
                'language': 'tr'
            },
            'style_profile': {
                'user_preferences': {'style': 'sporty', 'occasion': 'casual'},
                'wardrobe_analysis': {'items': [{'type': 'shirt', 'color': 'blue'}]}
            },
            'combination_engine': {
                'style_profile': {'style_type': 'sporty'},
                'occasion': 'casual',
                'weather': 'sunny'
            },
            'recommendation': {
                'user_profile': {'style': 'sporty'},
                'combinations': [{'type': 'casual', 'items': []}],
                'budget_range': 'medium'
            }
        }
        return data.get(service_name, {})
    
    def get_ai_endpoint(self, service_name: str) -> str:
        """AI servisinin ana endpoint'i"""
        endpoints = {
            'image_processing': '/analyze',
            'nlu': '/parse_request', 
            'style_profile': '/create_profile',
            'combination_engine': '/generate_combinations',
            'recommendation': '/get_recommendations'
        }
        return endpoints.get(service_name, '/')
    
    def validate_ai_output(self, service_name: str, output: dict) -> dict:
        """AI Ã§Ä±ktÄ±sÄ±nÄ±n mantÄ±klÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol et"""
        
        if not output or not isinstance(output, dict):
            return {'valid': False, 'reason': 'BoÅŸ veya geÃ§ersiz Ã§Ä±ktÄ±'}
        
        # Genel validasyonlar
        if service_name == 'image_processing':
            if any(key in output for key in ['detected_items', 'items', 'clothing_items', 'analysis', 'result']):
                return {'valid': True, 'reason': 'GÃ¶rÃ¼ntÃ¼ analiz alanlarÄ± mevcut'}
        
        elif service_name == 'nlu':
            if any(key in output for key in ['intent', 'entities', 'parsed_request', 'analysis']):
                return {'valid': True, 'reason': 'NLU alanlarÄ± mevcut'}
        
        elif service_name == 'style_profile':
            if any(key in output for key in ['style_profile', 'profile', 'style_type', 'style']):
                return {'valid': True, 'reason': 'Stil profili alanlarÄ± mevcut'}
        
        elif service_name == 'combination_engine':
            if any(key in output for key in ['combinations', 'outfits', 'suggestions']):
                return {'valid': True, 'reason': 'Kombinasyon alanlarÄ± mevcut'}
        
        elif service_name == 'recommendation':
            if any(key in output for key in ['recommendations', 'products', 'suggestions']):
                return {'valid': True, 'reason': 'Ã–neri alanlarÄ± mevcut'}
        
        # En azÄ±ndan bazÄ± veri var
        if len(output.keys()) > 0:
            return {'valid': True, 'reason': f'Veri mevcut: {list(output.keys())[:3]}'}
        
        return {'valid': False, 'reason': 'Beklenen alanlar bulunamadÄ±'}
    
    def run_unit_tests(self):
        """Unit testleri Ã§alÄ±ÅŸtÄ±r"""
        start_time = time.time()
        
        try:
            # Test dosyalarÄ±nÄ± bul
            test_files = []
            for root, dirs, files in os.walk(self.workspace_path):
                for file in files:
                    if file.startswith('test_') and file.endswith('.py'):
                        test_files.append(os.path.join(root, file))
            
            if not test_files:
                self.add_test_result(
                    "Unit Tests Discovery",
                    "UNIT_TESTS",
                    "SKIP",
                    "HiÃ§bir unit test dosyasÄ± bulunamadÄ±",
                    time.time() - start_time,
                    {"searched_directory": self.workspace_path}
                )
                return
            
            # Her test dosyasÄ± iÃ§in
            for test_file in test_files[:5]:  # Ä°lk 5 test dosyasÄ±
                file_start = time.time()
                try:
                    # Pytest ile testi Ã§alÄ±ÅŸtÄ±r
                    result = subprocess.run(
                        [sys.executable, '-m', 'pytest', test_file, '-v'],
                        capture_output=True,
                        text=True,
                        timeout=60,
                        cwd=self.workspace_path
                    )
                    
                    execution_time = time.time() - file_start
                    
                    if result.returncode == 0:
                        status = "PASS"
                        message = f"Unit testler baÅŸarÄ±lÄ± - {os.path.basename(test_file)}"
                    else:
                        status = "FAIL"
                        message = f"Unit testler baÅŸarÄ±sÄ±z - {os.path.basename(test_file)}"
                    
                    self.add_test_result(
                        f"Unit Tests - {os.path.basename(test_file)}",
                        "UNIT_TESTS",
                        status,
                        message,
                        execution_time,
                        {
                            "test_file": test_file,
                            "return_code": result.returncode,
                            "stdout_length": len(result.stdout),
                            "stderr_length": len(result.stderr)
                        }
                    )
                    
                except subprocess.TimeoutExpired:
                    self.add_test_result(
                        f"Unit Tests - {os.path.basename(test_file)}",
                        "UNIT_TESTS",
                        "FAIL",
                        "Test timeout (60s)",
                        60.0,
                        {"test_file": test_file}
                    )
                except Exception as e:
                    self.add_test_result(
                        f"Unit Tests - {os.path.basename(test_file)}",
                        "UNIT_TESTS",
                        "ERROR",
                        f"Test Ã§alÄ±ÅŸtÄ±rma hatasÄ±: {str(e)}",
                        time.time() - file_start,
                        {"test_file": test_file}
                    )
                
        except Exception as e:
            self.add_test_result(
                "Unit Tests Execution",
                "UNIT_TESTS", 
                "ERROR",
                f"Unit test hatasÄ±: {str(e)}",
                time.time() - start_time,
                {}
            )
    
    def run_all_tests(self):
        """TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r"""
        print("\nğŸš€ KAPSAMLI TEST SÃœRECÄ° BAÅLATIYOR")
        print("=" * 80)
        
        # 1. SaÄŸlÄ±k testleri
        print("\nğŸ¥ 1/6 - Servis SaÄŸlÄ±k Testleri...")
        for service_name, url in self.services.items():
            self.test_service_health(service_name, url)
            time.sleep(0.2)
        
        # 2. API endpoint testleri
        print("\nğŸ”Œ 2/6 - API Endpoint Testleri...")
        for service_name, url in self.services.items():
            self.test_api_endpoints(service_name, url) 
            time.sleep(0.5)
        
        # 3. Performans testleri
        print("\nâš¡ 3/6 - Performans Testleri...")
        for service_name, url in self.services.items():
            self.test_service_performance(service_name, url)
            time.sleep(0.3)
        
        # 4. End-to-End testleri
        print("\nğŸ”„ 4/6 - End-to-End Testleri...")
        self.test_end_to_end_workflow()
        
        # 5. AI model validation testleri
        print("\nğŸ¤– 5/6 - AI Model DoÄŸrulama Testleri...")
        self.test_ai_model_outputs()
        
        # 6. Unit testleri
        print("\nğŸ”¬ 6/6 - Unit Testleri...")
        self.run_unit_tests()
        
        # Test sonuÃ§larÄ±nÄ± analiz et
        return self.analyze_results()
    
    def analyze_results(self) -> dict:
        """Test sonuÃ§larÄ±nÄ± analiz et ve rapor oluÅŸtur"""
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results if r['status'] == "PASS"])
        failed_tests = len([r for r in self.test_results if r['status'] == "FAIL"])
        error_tests = len([r for r in self.test_results if r['status'] == "ERROR"])
        skipped_tests = len([r for r in self.test_results if r['status'] == "SKIP"])
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        # Kategori bazÄ±nda analiz
        categories = ["INTEGRATION_TESTS", "PERFORMANCE_TESTS", "END_TO_END_TESTS", "AI_VALIDATION_TESTS", "UNIT_TESTS"]
        category_stats = {}
        
        for category in categories:
            category_tests = [r for r in self.test_results if r['category'] == category]
            if category_tests:
                category_passed = len([r for r in category_tests if r['status'] == "PASS"])
                category_total = len(category_tests)
                category_success = (category_passed / category_total * 100) if category_total > 0 else 0
                
                category_stats[category] = {
                    'total': category_total,
                    'passed': category_passed,
                    'failed': len([r for r in category_tests if r['status'] == "FAIL"]),
                    'errors': len([r for r in category_tests if r['status'] == "ERROR"]),
                    'skipped': len([r for r in category_tests if r['status'] == "SKIP"]),
                    'success_rate': category_success
                }
        
        # BaÅŸarÄ±sÄ±z testleri analiz et
        failed_tests_detail = []
        for result in self.test_results:
            if result['status'] in ["FAIL", "ERROR"]:
                failed_tests_detail.append({
                    'test_name': result['test_name'],
                    'category': result['category'],
                    'status': result['status'],
                    'message': result['message']
                })
        
        # Performans istatistikleri
        performance_stats = {
            'avg_execution_time': sum(r['execution_time'] for r in self.test_results) / total_tests if total_tests > 0 else 0,
            'max_execution_time': max((r['execution_time'] for r in self.test_results), default=0),
            'min_execution_time': min((r['execution_time'] for r in self.test_results), default=0)
        }
        
        # MÃ¼kemmellik skoru hesapla
        perfection_score = self.calculate_perfection_score()
        
        return {
            'summary': {
                'total_tests': total_tests,
                'passed': passed_tests,
                'failed': failed_tests,
                'errors': error_tests,
                'skipped': skipped_tests,
                'success_rate': success_rate,
                'perfection_score': perfection_score
            },
            'category_stats': category_stats,
            'failed_tests': failed_tests_detail,
            'performance_stats': performance_stats,
            'execution_time': (datetime.now() - self.start_time).total_seconds(),
            'timestamp': datetime.now().isoformat(),
            'all_results': self.test_results
        }
    
    def calculate_perfection_score(self) -> float:
        """MÃ¼kemmellik skoru hesapla"""
        if not self.test_results:
            return 0.0
        
        # AÄŸÄ±rlÄ±klÄ± skorlama sistemi
        weights = {
            "PASS": 1.0,
            "SKIP": 0.5,  # GeÃ§ilen testler kÄ±smi puan
            "FAIL": 0.0,
            "ERROR": 0.0
        }
        
        # Kategori aÄŸÄ±rlÄ±klarÄ±
        category_weights = {
            "UNIT_TESTS": 0.15,
            "INTEGRATION_TESTS": 0.30,
            "END_TO_END_TESTS": 0.25,
            "PERFORMANCE_TESTS": 0.15,
            "AI_VALIDATION_TESTS": 0.15
        }
        
        total_weighted_score = 0.0
        total_weight = 0.0
        
        categories = ["INTEGRATION_TESTS", "PERFORMANCE_TESTS", "END_TO_END_TESTS", "AI_VALIDATION_TESTS", "UNIT_TESTS"]
        
        for category in categories:
            category_tests = [r for r in self.test_results if r['category'] == category]
            if category_tests:
                category_score = sum(weights.get(r['status'], 0) for r in category_tests) / len(category_tests)
                category_weight = category_weights.get(category, 0.01)
                
                total_weighted_score += category_score * category_weight
                total_weight += category_weight
        
        perfection_score = (total_weighted_score / total_weight * 100) if total_weight > 0 else 0.0
        return round(perfection_score, 1)
    
    def print_final_report(self, analysis: dict):
        """Final raporu yazdÄ±r"""
        print("\n" + "="*80)
        print("ğŸ† ULTIMATE PERFECTION TEST - FINAL RAPORU")
        print("="*80)
        
        summary = analysis['summary']
        print(f"\nğŸ“Š GENEL Ã–ZET:")
        print(f"   ğŸ”¢ Toplam Test: {summary['total_tests']}")
        print(f"   âœ… BaÅŸarÄ±lÄ±: {summary['passed']}")
        print(f"   âŒ BaÅŸarÄ±sÄ±z: {summary['failed']}")
        print(f"   ğŸš¨ Hata: {summary['errors']}")
        print(f"   â­ï¸ GeÃ§ilen: {summary['skipped']}")
        print(f"   ğŸ“ˆ BaÅŸarÄ± OranÄ±: %{summary['success_rate']:.1f}")
        print(f"   ğŸ¯ MÃ¼kemmellik Skoru: %{summary['perfection_score']:.1f}")
        
        print(f"\nğŸ“‹ KATEGORÄ° BAZLI ANALIZ:")
        for category, stats in analysis['category_stats'].items():
            print(f"   {category}:")
            print(f"      â€¢ Toplam: {stats['total']} | BaÅŸarÄ±lÄ±: {stats['passed']} | BaÅŸarÄ±: %{stats['success_rate']:.1f}")
        
        if analysis['failed_tests']:
            print(f"\nâŒ BAÅARISIZ TESTLER ({len(analysis['failed_tests'])}):")
            for i, test in enumerate(analysis['failed_tests'][:10], 1):  # Ä°lk 10 hata
                print(f"   {i}. [{test['category']}] {test['test_name']}")
                print(f"      â¤ {test['message']}")
        
        print(f"\nâš¡ PERFORMANS Ä°STATÄ°STÄ°KLERÄ°:")
        perf = analysis['performance_stats']
        print(f"   â€¢ Ortalama: {perf['avg_execution_time']:.3f}s")
        print(f"   â€¢ Maksimum: {perf['max_execution_time']:.3f}s")
        print(f"   â€¢ Minimum: {perf['min_execution_time']:.3f}s")
        
        print(f"\nâ±ï¸ TOPLAM Ã‡ALIÅMA SÃœRESÄ°: {analysis['execution_time']:.1f} saniye")
        
        # MÃ¼kemmellik deÄŸerlendirmesi
        perfection_score = summary['perfection_score']
        if perfection_score >= 100.0:
            print(f"\nğŸ† SONUÃ‡: MUTLAK MÃœKEMMELLÄ°K BAÅARILDI! (%{perfection_score:.1f})")
            print("ğŸ‰ Sistem production'a hazÄ±r!")
        elif perfection_score >= 95.0:
            print(f"\nğŸ¥ˆ SONUÃ‡: NEREDEYSE MÃœKEMMELLÄ°K (%{perfection_score:.1f})")
            print("ğŸ”§ KÃ¼Ã§Ã¼k dÃ¼zeltmelerle %100'e ulaÅŸÄ±labilir!")
        elif perfection_score >= 90.0:
            print(f"\nğŸ¥‰ SONUÃ‡: Ä°YÄ° DURUM (%{perfection_score:.1f})")
            print("âš ï¸ BazÄ± kritik iyileÅŸtirmeler gerekiyor.")
        else:
            print(f"\nâš ï¸ SONUÃ‡: Ä°YÄ°LEÅTÄ°RME GEREKÄ°YOR (%{perfection_score:.1f})")
            print("ğŸ”§ Sistemde Ã¶nemli dÃ¼zeltmeler yapÄ±lmalÄ±.")
        
        print("\n" + "="*80)
        
        return analysis

def main():
    """Ana test fonksiyonu"""
    tester = UltimatePerfectionTesterSimple()
    
    print("ğŸ¯ ULTIMATE PERFECTION TESTER (Simple)")
    print("Sistem kusursuzluÄŸu iÃ§in kapsamlÄ± test sÃ¼reci baÅŸlÄ±yor...")
    print("Bu iÅŸlem 3-5 dakika sÃ¼rebilir.\n")
    
    try:
        # TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r
        analysis = tester.run_all_tests()
        
        # Final raporu yazdÄ±r
        final_report = tester.print_final_report(analysis)
        
        # SonuÃ§larÄ± kaydet
        with open('ULTIMATE_PERFECTION_REPORT.json', 'w', encoding='utf-8') as f:
            json.dump(analysis, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ DetaylÄ± rapor kaydedildi: ULTIMATE_PERFECTION_REPORT.json")
        
        return analysis
        
    except Exception as e:
        print(f"\nğŸš¨ KRITIK HATA: {str(e)}")
        print(f"ğŸ“‹ Hata detayÄ±: {traceback.format_exc()}")
        return None

if __name__ == "__main__":
    main()
