# üéØ Multi-Modal Coordinator Service - FastAPI Main Application
# AURA AI √áok Modlu Sorgu Koordinat√∂r√º API Servisi

"""
Multi-Modal Coordinator Service - Ana FastAPI Uygulamasƒ±

Bu servis AURA AI sisteminin √ßok modlu sorgu i≈üleme yeteneklerini REST API 
olarak sunar. Kullanƒ±cƒ±lar g√∂rsel ve metin verilerini birlikte g√∂ndererek
akƒ±llƒ± moda √∂nerileri alabilirler.

Port: 8009
√ñzellikler:
- √áok modlu sorgu i≈üleme (g√∂rsel + metin)
- CLIP tabanlƒ± g√∂rsel analiz
- NLU tabanlƒ± metin analizi
- Real-time service koordinasyonu
- Quality assurance entegrasyonu
"""

import logging
import asyncio
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
import base64
import json

# FastAPI ve HTTP imports
from fastapi import FastAPI, HTTPException, UploadFile, File, Form, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import uvicorn

# Multi-modal engine import
from multi_modal_engine import (
    MultiModalCoordinator,
    MultiModalQueryRequest,
    MultiModalQueryResponse,
    process_query
)

# Logging konfig√ºrasyonu - Production-ready logging setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # Console output i√ßin
        logging.FileHandler('multi_modal_coordinator.log')  # File logging i√ßin
    ]
)
logger = logging.getLogger("multi_modal_api")

# FastAPI uygulamasƒ± olu≈ütur - Comprehensive metadata ile
app = FastAPI(
    title="AURA AI Multi-Modal Coordinator Service",
    description="""
    üéØ AURA AI √áok Modlu Sorgu Koordinat√∂r√º
    
    Bu servis kullanƒ±cƒ±larƒ±n g√∂rsel ve metin verilerini birle≈ütirerek
    akƒ±llƒ± moda √∂nerileri almalarƒ±nƒ± saƒülar.
    
    **√ñzellikler:**
    - üì∏ G√∂rsel analiz (CLIP tabanlƒ±)
    - üß† Metin analizi (NLU tabanlƒ±)
    - üîÑ Context fusion ve semantic integration
    - üé® Multi-service coordination
    - üõ°Ô∏è Quality assurance validation
    
    **Desteklenen Sorgu Tipleri:**
    - "Bu g√∂mlekle ne giyebilirim?" 
    - "Bu elbiseye uygun ayakkabƒ± var mƒ±?"
    - "Bu pantolonla hangi ceketi √∂nerirsin?"
    - "Bu √ßantayla ne kombin olur?"
    """,
    version="1.0.0",
    contact={
        "name": "AURA AI Development Team",
        "email": "dev@aura-ai.com"
    },
    license_info={
        "name": "MIT License",
        "url": "https://opensource.org/licenses/MIT"
    }
)

# CORS middleware ekleme - Cross-origin requests i√ßin
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Production'da specific domains olacak
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global coordinator instance - Servis ba≈ülatƒ±ldƒ±ƒüƒ±nda bir kez olu≈üturulur
coordinator_instance: Optional[MultiModalCoordinator] = None

# Request modelleri - API endpoint'leri i√ßin
class HealthResponse(BaseModel):
    """Health check response modeli"""
    service: str = "AURA AI Multi-Modal Coordinator Service"
    status: str
    timestamp: str
    version: str = "1.0.0"
    components: Dict[str, str]
    active_connections: int
    processing_capabilities: List[str]

class ImageUploadQueryRequest(BaseModel):
    """File upload ile multi-modal query request modeli"""
    text_query: str = Field(..., description="User's text query", min_length=1, max_length=500)
    user_id: Optional[str] = Field(None, description="User ID for personalization")
    context: Optional[Dict[str, Any]] = Field(default_factory=dict, description="Additional context")

class QueryStatsResponse(BaseModel):
    """Query istatistikleri response modeli"""
    total_queries_processed: int
    average_processing_time_ms: float
    success_rate_percent: float
    most_common_query_types: List[str]
    active_since: str

# Startup event - Servis ba≈ülatƒ±ldƒ±ƒüƒ±nda √ßalƒ±≈üƒ±r
@app.on_event("startup")
async def startup_event():
    """
    Servis ba≈ülatƒ±ldƒ±ƒüƒ±nda gerekli initialization'larƒ± yapar
    Multi-modal coordinator'ƒ± ba≈ülatƒ±r ve baƒülantƒ±larƒ± kontrol eder
    """
    global coordinator_instance
    
    logger.info("üöÄ Multi-Modal Coordinator Service starting up...")
    
    try:
        # Coordinator instance'ƒ±nƒ± olu≈ütur
        coordinator_instance = MultiModalCoordinator()
        
        # Service health check'leri yap
        await _perform_startup_health_checks()
        
        logger.info("‚úÖ Multi-Modal Coordinator Service started successfully")
        logger.info("üîó Service available at: http://localhost:8009")
        logger.info("üìö API documentation at: http://localhost:8009/docs")
        
    except Exception as e:
        logger.error(f"‚ùå Startup failed: {str(e)}")
        raise

# Shutdown event - Servis kapatƒ±ldƒ±ƒüƒ±nda temizlik yapar
@app.on_event("shutdown")
async def shutdown_event():
    """
    Servis kapatƒ±ldƒ±ƒüƒ±nda temizlik i≈ülemlerini yapar
    A√ßƒ±k baƒülantƒ±larƒ± kapatƒ±r ve resources'larƒ± temizler
    """
    logger.info("üîÑ Multi-Modal Coordinator Service shutting down...")
    
    try:
        # HTTP client'larƒ± kapat
        if coordinator_instance and hasattr(coordinator_instance, 'http_client'):
            await coordinator_instance.http_client.aclose()
        
        logger.info("‚úÖ Multi-Modal Coordinator Service shutdown completed")
        
    except Exception as e:
        logger.error(f"‚ùå Shutdown error: {str(e)}")

async def _perform_startup_health_checks():
    """Startup sƒ±rasƒ±nda critical servislerin health check'ini yapar"""
    logger.info("üîç Performing startup health checks...")
    
    # Critical services listesi
    critical_services = [
        ("NLU Service", "http://localhost:8002"),
        ("Image Processing", "http://localhost:8001"),
        ("Quality Assurance", "http://localhost:8008")
    ]
    
    import httpx
    async with httpx.AsyncClient(timeout=5.0) as client:
        for service_name, service_url in critical_services:
            try:
                response = await client.get(f"{service_url}/", timeout=3.0)
                if response.status_code == 200:
                    logger.info(f"‚úÖ {service_name} is available")
                else:
                    logger.warning(f"‚ö†Ô∏è {service_name} returned status {response.status_code}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è {service_name} health check failed: {str(e)}")

# Health check endpoint - Servis durumunu kontrol eder
@app.get("/", response_model=HealthResponse, tags=["Health"])
async def health_check():
    """
    Multi-Modal Coordinator servisinin health durumunu d√∂nd√ºr√ºr
    
    Bu endpoint servisin √ßalƒ±≈üƒ±r durumda olduƒüunu ve
    t√ºm bile≈üenlerinin hazƒ±r olduƒüunu kontrol eder.
    """
    logger.info("üè• Health check requested")
    
    try:
        # Component status'larƒ± kontrol et
        components_status = {
            "CLIP_Processor": "operational" if coordinator_instance else "not_initialized",
            "NLU_Processor": "operational" if coordinator_instance else "not_initialized", 
            "Context_Fusion_Engine": "operational" if coordinator_instance else "not_initialized",
            "Service_Coordinator": "operational" if coordinator_instance else "not_initialized"
        }
        
        # Genel status belirle
        overall_status = "healthy" if all(status == "operational" for status in components_status.values()) else "degraded"
        
        response = HealthResponse(
            status=overall_status,
            timestamp=datetime.now().isoformat(),
            components=components_status,
            active_connections=1,  # Ger√ßek implementasyonda connection pool'dan alƒ±nacak
            processing_capabilities=[
                "Multi-modal query processing",
                "CLIP-based visual analysis", 
                "NLU-based text analysis",
                "Context fusion and semantic integration",
                "Multi-service coordination",
                "Quality assurance validation"
            ]
        )
        
        logger.info(f"‚úÖ Health check completed: {overall_status}")
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Health check failed: {str(e)}")
        raise HTTPException(status_code=503, detail=f"Health check failed: {str(e)}")

# Ana multi-modal query endpoint - Base64 ile g√∂rsel g√∂nderme
@app.post("/query", response_model=MultiModalQueryResponse, tags=["Multi-Modal Query"])
async def process_multimodal_query(request: MultiModalQueryRequest):
    """
    √áok modlu sorgu i≈üleme endpoint'i - Base64 encoded image ile
    
    Kullanƒ±cƒ±dan gelen g√∂rsel (base64) ve metin verisini i≈üleyerek
    akƒ±llƒ± moda √∂nerileri √ºretir.
    
    **Request Format:**
    - image_base64: Base64 encoded image data
    - text_query: User's text query (e.g., "Bu g√∂mlekle ne giyebilirim?")
    - user_id: Optional user ID for personalization
    - context: Additional context data
    
    **Response:**
    - Unified intent analysis
    - Visual and textual analysis results
    - Personalized recommendations
    - Quality-assured suggestions
    """
    logger.info(f"üéØ Multi-modal query request received")
    logger.info(f"üìù Query: '{request.text_query}'")
    
    # Coordinator hazƒ±r mƒ± kontrol et
    if not coordinator_instance:
        logger.error("‚ùå Coordinator not initialized")
        raise HTTPException(status_code=503, detail="Multi-modal coordinator not available")
    
    try:
        # Query'yi process et
        response = await coordinator_instance.process_multimodal_query(request)
        
        logger.info(f"‚úÖ Query processed successfully: {response.query_id}")
        return response
        
    except HTTPException:
        # HTTP exceptions'larƒ± re-raise et
        raise
    except Exception as e:
        logger.error(f"‚ùå Multi-modal query processing failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Query processing failed: {str(e)}")

# File upload ile multi-modal query endpoint
@app.post("/query/upload", response_model=MultiModalQueryResponse, tags=["Multi-Modal Query"])
async def process_multimodal_query_with_upload(
    image: UploadFile = File(..., description="Image file (JPEG, PNG, JPG, WEBP)"),
    text_query: str = Form(..., description="User's text query"),
    user_id: Optional[str] = Form(None, description="User ID for personalization"),
    context: str = Form("{}", description="Additional context as JSON string")
):
    """
    √áok modlu sorgu i≈üleme endpoint'i - File upload ile
    
    Kullanƒ±cƒ±dan gelen g√∂rsel dosyayƒ± ve metin verisini i≈üleyerek
    akƒ±llƒ± moda √∂nerileri √ºretir.
    
    **Supported Image Formats:** JPEG, PNG, JPG, WEBP
    **Max File Size:** 10MB
    """
    logger.info(f"üì§ Multi-modal query with file upload received")
    logger.info(f"üìù Query: '{text_query}'")
    logger.info(f"üñºÔ∏è Image: {image.filename} ({image.content_type})")
    
    # Coordinator hazƒ±r mƒ± kontrol et
    if not coordinator_instance:
        logger.error("‚ùå Coordinator not initialized") 
        raise HTTPException(status_code=503, detail="Multi-modal coordinator not available")
    
    try:
        # Image dosyasƒ±nƒ± oku ve validate et
        image_data = await image.read()
        
        # Dosya boyutu kontrol√º (10MB limit)
        if len(image_data) > 10 * 1024 * 1024:
            raise HTTPException(status_code=413, detail="Image file too large (max 10MB)")
        
        # Content type kontrol√º
        allowed_types = ["image/jpeg", "image/png", "image/jpg", "image/webp"]
        if image.content_type not in allowed_types:
            raise HTTPException(status_code=415, detail=f"Unsupported image type: {image.content_type}")
        
        # Context JSON'ƒ±nƒ± parse et
        try:
            context_dict = json.loads(context) if context != "{}" else {}
        except json.JSONDecodeError:
            raise HTTPException(status_code=400, detail="Invalid context JSON format")
        
        # Base64 encode et
        image_base64 = base64.b64encode(image_data).decode('utf-8')
        
        # MultiModalQueryRequest olu≈ütur
        query_request = MultiModalQueryRequest(
            image_base64=image_base64,
            text_query=text_query,
            user_id=user_id,
            context=context_dict
        )
        
        # Query'yi process et
        response = await coordinator_instance.process_multimodal_query(query_request)
        
        logger.info(f"‚úÖ File upload query processed successfully: {response.query_id}")
        return response
        
    except HTTPException:
        # HTTP exceptions'larƒ± re-raise et
        raise
    except Exception as e:
        logger.error(f"‚ùå File upload query processing failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"File upload query processing failed: {str(e)}")

# Test scenarios endpoint - Built-in test senaryolarƒ±
@app.post("/test-nlu-advanced", tags=["Testing"])
async def test_nlu_advanced():
    """
    Bu endpoint geli≈ümi≈ü NLU √∂zelliklerini test eder.
    4 farklƒ± prompt engineering pattern ile NLU analizini deƒüerlendirir.
    """
    logger.info("üß† Testing advanced NLU capabilities...")
    
    # Coordinator hazƒ±r mƒ± kontrol et
    if not coordinator_instance:
        raise HTTPException(status_code=503, detail="Multi-modal coordinator not available")
    
    # Geli≈ümi≈ü NLU test senaryolarƒ±
    nlu_test_queries = [
        {
            "query": "Bu g√∂mlekle hangi pantolon uyumlu olur acaba?",
            "expected_pattern": "Template",
            "expected_intent": "kombin_√∂nerisi_isteme"
        },
        {
            "query": "Siyah ayakkabƒ±mla bu eteƒüi giyebilir miyim?",
            "expected_pattern": "Context & Instruction", 
            "expected_intent": "uyum_kontrol√º"
        },
        {
            "query": "ƒ∞≈ü toplantƒ±sƒ±na bu kƒ±yafetle gidebilir miyim?",
            "expected_pattern": "Persona",
            "expected_intent": "durum_uygunluk_sorgulama"
        },
        {
            "query": "Bu ceketin altƒ±na ne giymeliyim step by step anlat",
            "expected_pattern": "Recipe",
            "expected_intent": "adƒ±m_adƒ±m_kombin_rehberi"
        }
    ]
    
    # Test sonu√ßlarƒ±nƒ± topla
    nlu_results = []
    successful_tests = 0
    
    for i, test_case in enumerate(nlu_test_queries, 1):
        logger.info(f"üî¨ Testing advanced NLU pattern {i}/{len(nlu_test_queries)}")
        
        try:
            # NLU processor'ƒ± test et
            start_time = time.time()
            nlu_result = await coordinator_instance.nlu_processor._mock_nlu_analysis(test_case["query"], {})
            processing_time = (time.time() - start_time) * 1000
            
            # Sonu√ßlarƒ± analiz et
            detected_intent = nlu_result.intent
            confidence = nlu_result.confidence_score
            entities = nlu_result.entities
            sentiment = nlu_result.sentiment
            prompt_pattern = "Advanced NLU Pattern"  # Mock for now
            
            # Test ba≈üarƒ±sƒ±nƒ± deƒüerlendir
            intent_correct = test_case["expected_intent"] in detected_intent
            pattern_correct = test_case["expected_pattern"] in prompt_pattern
            high_confidence = confidence > 0.8
            
            test_success = intent_correct and high_confidence
            
            # Sonucu kaydet
            test_result = {
                "test_query": test_case["query"],
                "expected_intent": test_case["expected_intent"],
                "detected_intent": detected_intent,
                "expected_pattern": test_case["expected_pattern"],
                "used_pattern": prompt_pattern,
                "confidence_score": confidence,
                "entities_found": len(entities),
                "sentiment_analysis": sentiment,
                "processing_time_ms": round(processing_time, 3),
                "intent_accuracy": intent_correct,
                "pattern_accuracy": pattern_correct,
                "confidence_level": "high" if high_confidence else "medium" if confidence > 0.6 else "low",
                "overall_success": test_success
            }
            
            nlu_results.append(test_result)
            
            if test_success:
                successful_tests += 1
                logger.info(f"‚úÖ Advanced NLU test {i} passed")
            else:
                logger.warning(f"‚ö†Ô∏è Advanced NLU test {i} needs improvement")
                
        except Exception as e:
            logger.error(f"‚ùå Advanced NLU test {i} failed: {str(e)}")
            nlu_results.append({
                "test_query": test_case["query"],
                "error": str(e),
                "overall_success": False
            })
    
    # Genel istatistikler
    success_rate = (successful_tests / len(nlu_test_queries)) * 100
    successful_results = [r for r in nlu_results if "confidence_score" in r]
    avg_confidence = sum(r.get("confidence_score", 0) for r in successful_results) / len(successful_results) if successful_results else 0
    avg_processing_time = sum(r.get("processing_time_ms", 0) for r in successful_results) / len(successful_results) if successful_results else 0
    
    logger.info(f"üéØ Advanced NLU testing completed: {successful_tests}/{len(nlu_test_queries)} passed ({success_rate:.1f}%)")
    
    return {
        "nlu_test_summary": {
            "total_tests": len(nlu_test_queries),
            "successful_tests": successful_tests, 
            "success_rate_percent": success_rate,
            "average_confidence": round(avg_confidence, 3),
            "average_processing_time_ms": round(avg_processing_time, 3),
            "nlu_status": "excellent" if success_rate >= 90 else "good" if success_rate >= 75 else "needs_improvement"
        },
        "detailed_results": nlu_results,
        "prompt_engineering_assessment": {
            "persona_pattern_usage": len([r for r in nlu_results if "Persona" in r.get("used_pattern", "")]),
            "recipe_pattern_usage": len([r for r in nlu_results if "Recipe" in r.get("used_pattern", "")]),
            "template_pattern_usage": len([r for r in nlu_results if "Template" in r.get("used_pattern", "")]),
            "context_instruction_usage": len([r for r in nlu_results if "Context" in r.get("used_pattern", "")])
        },
        "recommendations": [
            f"NLU confidence average: {avg_confidence:.1f}",
            f"Processing speed: {avg_processing_time:.1f}ms per query",
            "Advanced prompt engineering patterns working effectively" if success_rate >= 80 else "Prompt patterns need refinement"
        ]
    }

@app.post("/test-scenarios", tags=["Testing"])
async def run_test_scenarios():
    """
    Built-in test senaryolarƒ±nƒ± √ßalƒ±≈ütƒ±rƒ±r
    
    √áok modlu sorgu sisteminin doƒüru √ßalƒ±≈ütƒ±ƒüƒ±nƒ± doƒürulamak i√ßin
    √∂nceden tanƒ±mlƒ± test senaryolarƒ±nƒ± √ßalƒ±≈ütƒ±rƒ±r.
    """
    logger.info("üß™ Running multi-modal test scenarios...")
    
    # Coordinator hazƒ±r mƒ± kontrol et
    if not coordinator_instance:
        raise HTTPException(status_code=503, detail="Multi-modal coordinator not available")
    
    try:
        # Test senaryolarƒ± tanƒ±mla
        test_scenarios = [
            {
                "name": "G√∂mlek Kombinasyon Testi",
                "text_query": "Bu mavi g√∂mlekle ne giyebilirim?",
                "expected_intent": "kombin_√∂nerisi_isteme",
                "description": "Mavi g√∂mlek ile alt par√ßa kombinasyonu"
            },
            {
                "name": "Elbise Ayakkabƒ± Uyum Testi", 
                "text_query": "Bu siyah elbiseye uygun ayakkabƒ± var mƒ±?",
                "expected_intent": "ayakkabƒ±_uyumu_sorgulama",
                "description": "Siyah elbise ile ayakkabƒ± uyumu kontrol√º"
            },
            {
                "name": "Pantolon Ceket Kombinasyon Testi",
                "text_query": "Bu lacivert pantolonla hangi ceketi √∂nerirsin?",
                "expected_intent": "ceket_√∂nerisi_isteme", 
                "description": "Lacivert pantolon ile ceket kombinasyonu"
            }
        ]
        
        # Mock image data - Test i√ßin basit bir placeholder image
        test_image_base64 = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg=="
        
        test_results = []
        successful_tests = 0
        
        # Her test senaryosunu √ßalƒ±≈ütƒ±r
        for i, scenario in enumerate(test_scenarios):
            logger.info(f"üî¨ Running test {i+1}/{len(test_scenarios)}: {scenario['name']}")
            
            try:
                # Test request'i olu≈ütur
                test_request = MultiModalQueryRequest(
                    image_base64=test_image_base64,
                    text_query=scenario["text_query"],
                    user_id="test_user",
                    context={"test_scenario": scenario["name"]}
                )
                
                # Query'yi process et
                result = await coordinator_instance.process_multimodal_query(test_request)
                
                # Sonucu deƒüerlendir
                intent_match = scenario["expected_intent"] in result.textual_analysis.get("intent", "")
                
                test_results.append({
                    "scenario_name": scenario["name"],
                    "query": scenario["text_query"],
                    "expected_intent": scenario["expected_intent"],
                    "actual_intent": result.textual_analysis.get("intent", "unknown"),
                    "intent_matches": intent_match,
                    "processing_time_ms": result.processing_time_ms,
                    "fusion_confidence": result.fusion_confidence,
                    "recommendations_count": len(result.recommendations),
                    "success": result.success and intent_match
                })
                
                if result.success and intent_match:
                    successful_tests += 1
                    logger.info(f"‚úÖ Test {i+1} passed")
                else:
                    logger.warning(f"‚ö†Ô∏è Test {i+1} needs attention")
                    
            except Exception as e:
                logger.error(f"‚ùå Test {i+1} failed: {str(e)}")
                test_results.append({
                    "scenario_name": scenario["name"],
                    "query": scenario["text_query"],
                    "error": str(e),
                    "success": False
                })
        
        # Test √∂zetini olu≈ütur
        success_rate = (successful_tests / len(test_scenarios)) * 100
        
        test_summary = {
            "total_scenarios": len(test_scenarios),
            "successful_tests": successful_tests,
            "success_rate_percent": success_rate,
            "test_timestamp": datetime.now().isoformat(),
            "system_status": "optimal" if success_rate >= 90 else "needs_attention" if success_rate >= 70 else "requires_improvement"
        }
        
        logger.info(f"üéØ Test scenarios completed: {successful_tests}/{len(test_scenarios)} passed ({success_rate:.1f}%)")
        
        return {
            "test_summary": test_summary,
            "individual_results": test_results,
            "recommendations": [
                "Test sonu√ßlarƒ± ba≈üarƒ±lƒ±" if success_rate >= 90 else "Sistem optimizasyonu gerekebilir",
                f"Ortalama i≈ülem s√ºresi: {sum(r.get('processing_time_ms', 0) for r in test_results if 'processing_time_ms' in r) / len([r for r in test_results if 'processing_time_ms' in r]):.1f}ms" if test_results else "No timing data"
            ]
        }
        
    except Exception as e:
        logger.error(f"‚ùå Test scenarios failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Test scenarios failed: {str(e)}")

# Query statistics endpoint - ƒ∞statistikler ve monitoring
@app.get("/stats", response_model=QueryStatsResponse, tags=["Monitoring"])
async def get_query_statistics():
    """
    Multi-modal query istatistiklerini d√∂nd√ºr√ºr
    
    Servisin performans metriklerini ve kullanƒ±m istatistiklerini saƒülar.
    """
    logger.info("üìä Query statistics requested")
    
    try:
        # Mock statistics - Ger√ßek implementasyonda database'den gelecek
        stats = QueryStatsResponse(
            total_queries_processed=42,
            average_processing_time_ms=1250.5,
            success_rate_percent=95.2,
            most_common_query_types=[
                "shirt_combination",
                "dress_shoe_matching", 
                "pants_jacket_pairing"
            ],
            active_since=datetime.now().isoformat()
        )
        
        logger.info("‚úÖ Query statistics retrieved successfully")
        return stats
        
    except Exception as e:
        logger.error(f"‚ùå Query statistics retrieval failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Statistics retrieval failed: {str(e)}")

# Service capabilities endpoint - Servis yetenekleri
@app.get("/capabilities", tags=["Information"])
async def get_service_capabilities():
    """
    Multi-Modal Coordinator servisinin yeteneklerini listeler
    
    Desteklenen query tipleri, image formatlarƒ± ve diƒüer
    teknik capabilities'leri d√∂nd√ºr√ºr.
    """
    logger.info("‚ÑπÔ∏è Service capabilities requested")
    
    capabilities = {
        "service_name": "AURA AI Multi-Modal Coordinator",
        "version": "1.0.0",
        "supported_query_types": [
            {
                "type": "shirt_combination",
                "description": "G√∂mlek ile kombin √∂nerileri",
                "example": "Bu g√∂mlekle ne giyebilirim?"
            },
            {
                "type": "dress_shoe_matching",
                "description": "Elbise-ayakkabƒ± uyum kontrol√º",
                "example": "Bu elbiseye uygun ayakkabƒ± var mƒ±?"
            },
            {
                "type": "pants_jacket_pairing",
                "description": "Pantolon-ceket kombinasyonu",
                "example": "Bu pantolonla hangi ceketi √∂nerirsin?"
            },
            {
                "type": "bag_outfit_styling",
                "description": "√áanta merkezli komple outfit",
                "example": "Bu √ßantayla ne kombin olur?"
            }
        ],
        "supported_image_formats": ["JPEG", "PNG", "JPG", "WEBP"],
        "max_image_size_mb": 10,
        "processing_capabilities": [
            "CLIP-based visual analysis",
            "NLU-based text analysis", 
            "Context fusion and semantic integration",
            "Multi-service coordination",
            "Quality assurance validation",
            "Real-time recommendation generation"
        ],
        "integration_services": [
            "Image Processing Service (8001)",
            "NLU Service (8002)",
            "Style Profile Service (8003)",
            "Combination Engine (8004)",
            "Recommendation Engine (8005)",
            "Quality Assurance Service (8008)"
        ],
        "response_format": {
            "unified_intent": "Kullanƒ±cƒ±nƒ±n birle≈ütirilmi≈ü niyeti",
            "visual_analysis": "G√∂rsel analiz sonucu",
            "textual_analysis": "Metin analiz sonucu", 
            "recommendations": "Ki≈üiselle≈ütirilmi≈ü √∂neriler",
            "fusion_confidence": "Birle≈ütirme g√ºven skoru"
        }
    }
    
    logger.info("‚úÖ Service capabilities retrieved successfully")
    return capabilities

# Error handlers - Comprehensive error handling
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """HTTP exception handler - Structured error responses"""
    logger.error(f"HTTP Exception: {exc.status_code} - {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": True,
            "status_code": exc.status_code,
            "message": exc.detail,
            "timestamp": datetime.now().isoformat(),
            "service": "multi_modal_coordinator"
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """General exception handler - Catch-all for unexpected errors"""
    logger.error(f"Unexpected error: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "error": True,
            "status_code": 500,
            "message": "Internal server error occurred",
            "timestamp": datetime.now().isoformat(),
            "service": "multi_modal_coordinator"
        }
    )

# Main execution - Development server
if __name__ == "__main__":
    logger.info("üöÄ Starting Multi-Modal Coordinator Service...")
    
    # Uvicorn server configuration
    uvicorn.run(
        "main:app",
        host="0.0.0.0",  # T√ºm network interface'lerinde dinle
        port=8009,       # Multi-Modal Coordinator port
        reload=True,     # Development i√ßin auto-reload
        log_level="info",
        access_log=True,
        reload_dirs=[".", "./multi_modal_engine.py"]  # ƒ∞zlenecek dosyalar
    )
