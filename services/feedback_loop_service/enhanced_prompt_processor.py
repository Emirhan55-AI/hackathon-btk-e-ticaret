# ğŸ§  AURA AI Feedback Loop - Enhanced Advanced Feedback Processor with Prompt Engineering
# GeliÅŸmiÅŸ Prompt Engineering KalÄ±plarÄ± ile GÃ¼Ã§lendirilmiÅŸ Feedback Ä°ÅŸleme Sistemi

"""
Bu modÃ¼l, AURA AI Feedback Loop Service iÃ§in geliÅŸmiÅŸ prompt engineering kalÄ±plarÄ±
ile desteklenmiÅŸ akÄ±llÄ± feedback iÅŸleme sistemi saÄŸlar.

Ã–zellikler:
- 4 Prompt Engineering Pattern (Persona, Recipe, Template, Context & Instruction)
- AkÄ±ÅŸ mÃ¼hendisliÄŸi ile koordine edilen servis iletiÅŸimi
- Ã‡ok boyutlu feedback analizi ve sÄ±nÄ±flandÄ±rmasÄ±
- GerÃ§ek zamanlÄ± Ã¶ÄŸrenme ve adaptasyon
- KapsamlÄ± performans izleme
"""

import asyncio
import time
import json
import logging
from typing import Dict, List, Any, Optional, Union, Tuple
from datetime import datetime
from enum import Enum
from dataclasses import dataclass, asdict
import uuid
import requests
from collections import defaultdict
import re

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PromptPattern(Enum):
    """Prompt Engineering Pattern tÃ¼rleri"""
    PERSONA = "persona"
    RECIPE = "recipe"
    TEMPLATE = "template"
    CONTEXT_INSTRUCTION = "context_instruction"

class FeedbackType(Enum):
    """Feedback tÃ¼rleri - TÃ¼rkÃ§e kullanÄ±cÄ± feedback'leri iÃ§in"""
    NEGATIVE_GENERAL = "negative_general"           # "beÄŸenmedim"
    COLOR_DISSATISFACTION = "color_dissatisfaction" # "renk uyumlu deÄŸil"
    OCCASION_INAPPROPRIATE = "occasion_inappropriate" # "uygun deÄŸildi" 
    REQUEST_SIMILAR = "request_similar"             # "benzer Ã¶neriler"
    POSITIVE_GENERAL = "positive_general"           # "beÄŸendim"
    STYLE_ISSUE = "style_issue"                     # "stil uygun deÄŸil"
    FIT_ISSUE = "fit_issue"                         # "beden uygun deÄŸil"
    PRICE_CONCERN = "price_concern"                 # "pahalÄ±"

@dataclass
class PromptEngineeringContext:
    """Prompt Engineering baÄŸlamÄ±"""
    pattern_type: PromptPattern
    confidence_score: float
    processing_time_ms: float
    persona_used: Optional[str] = None
    recipe_steps: Optional[List[str]] = None
    template_structure: Optional[Dict[str, Any]] = None
    context_variables: Optional[Dict[str, Any]] = None

@dataclass
class FeedbackAnalysisResult:
    """Feedback analiz sonucu"""
    feedback_type: FeedbackType
    confidence_score: float
    sentiment_analysis: Dict[str, float]
    extracted_features: Dict[str, Any]
    recommendations: List[str]
    prompt_engineering_context: PromptEngineeringContext
    service_coordination_plan: Dict[str, Any]
    user_response_strategy: Dict[str, Any]

class AdvancedPromptEngineeringProcessor:
    """GeliÅŸmiÅŸ Prompt Engineering ile Feedback Ä°ÅŸlemcisi"""
    
    def __init__(self):
        self.pattern_weights = {
            PromptPattern.PERSONA: 0.9,
            PromptPattern.RECIPE: 0.85,
            PromptPattern.TEMPLATE: 0.8,
            PromptPattern.CONTEXT_INSTRUCTION: 0.95
        }
        
        # TÃ¼rkÃ§e feedback pattern'larÄ±
        self.turkish_feedback_patterns = {
            FeedbackType.NEGATIVE_GENERAL: [
                r'(beÄŸen|hoÅŸ|sev)me(dim|medim|yorum)',
                r'(kÃ¶tÃ¼|berbat|Ã§irkin)',
                r'(uygun deÄŸil|gÃ¼zel deÄŸil)'
            ],
            FeedbackType.COLOR_DISSATISFACTION: [
                r'renk.{0,10}(uyumlu deÄŸil|uygun deÄŸil|hoÅŸ deÄŸil)',
                r'(renk|ton).{0,10}(beÄŸenmedim|sevmedim)',
                r'(renkler|tonlar).{0,10}(karÄ±ÅŸÄ±k|uyumsuz)'
            ],
            FeedbackType.OCCASION_INAPPROPRIATE: [
                r'(iÅŸ|toplantÄ±|resmi|Ã¶zel).{0,20}(uygun deÄŸil|uymuyor)',
                r'(ortam|durum|yer).{0,15}(uygun deÄŸil)',
                r'(formal|casual|spor).{0,15}(olmalÄ±|lazÄ±m)'
            ],
            FeedbackType.REQUEST_SIMILAR: [
                r'(benzer|aynÄ±|bÃ¶yle).{0,10}(istiyorum|Ã¶nerin|gÃ¶sterin)',
                r'(daha Ã§ok|daha fazla).{0,10}(bÃ¶yle|benzer)',
                r'(devam|sÃ¼rdÃ¼r).{0,10}(Ã¶ner|gÃ¶ster)'
            ]
        }
        
        # Persona kalÄ±plarÄ±
        self.persona_patterns = {
            "ai_style_expert": {
                "description": "AURA AI stil uzmanÄ± personas",
                "personality": "Deneyimli, empatik, Ã§Ã¶zÃ¼m odaklÄ± moda danÄ±ÅŸmanÄ±",
                "expertise": ["renk analizi", "stil uyumu", "durum uygunluÄŸu"],
                "communication_style": "SaygÄ±lÄ±, anlayÄ±ÅŸlÄ±, yapÄ±cÄ±"
            },
            "learning_specialist": {
                "description": "Ã–ÄŸrenme ve adaptasyon uzmanÄ±",
                "personality": "Analitik, meraklÄ±, sÃ¼rekli geliÅŸim odaklÄ±",
                "expertise": ["kullanÄ±cÄ± tercihleri", "davranÄ±ÅŸ analizi", "trend takibi"],
                "communication_style": "Veri odaklÄ±, Ã¶ÄŸrenmeye aÃ§Ä±k"
            }
        }
        
        # Recipe (Tarif) kalÄ±plarÄ±
        self.recipe_patterns = {
            "feedback_analysis_recipe": [
                "1. KullanÄ±cÄ± feedback'ini alÄ±n ve baÄŸlamÄ± analiz edin",
                "2. Duygusal tonu ve kategoriyi belirleyin", 
                "3. Spesifik Ã¶zellik eleÅŸtirilerini Ã§Ä±karÄ±n",
                "4. Ä°lgili servislere koordinasyon planÄ± hazÄ±rlayÄ±n",
                "5. KiÅŸiselleÅŸtirilmiÅŸ yanÄ±t stratejisi geliÅŸtirin",
                "6. Sistem Ã¶ÄŸrenmesi iÃ§in gÃ¼ncelleme planÄ± oluÅŸturun"
            ],
            "color_dissatisfaction_recipe": [
                "1. Renk kombinasyonu Ã¶zelliklerini analiz edin",
                "2. KullanÄ±cÄ±nÄ±n renk tercihlerini inceleyin",
                "3. Image Processing Service ile detaylÄ± analiz yapÄ±n",
                "4. Style Profile Service'i gÃ¼ncelleyin",
                "5. Alternatif renk Ã¶nerileri hazÄ±rlayÄ±n"
            ]
        }
        
        # Template kalÄ±plarÄ±
        self.template_patterns = {
            "feedback_analysis_template": {
                "user_input": "{user_feedback}",
                "context": "{context_information}",
                "analysis_steps": [
                    "sentiment_detection",
                    "category_classification", 
                    "feature_extraction",
                    "confidence_scoring"
                ],
                "output_structure": {
                    "feedback_type": "{classified_type}",
                    "confidence": "{confidence_score}",
                    "action_plan": "{service_coordination}",
                    "user_response": "{personalized_response}"
                }
            }
        }
        
        # Service endpoints
        self.service_endpoints = {
            "style_profile": "http://localhost:8003",
            "recommendation_engine": "http://localhost:8005",
            "quality_assurance": "http://localhost:8008",
            "nlu_service": "http://localhost:8004",
            "image_processing": "http://localhost:8002",
            "combination_engine": "http://localhost:8006"
        }
        
        logger.info("ğŸ§  Advanced Prompt Engineering Processor initialized")
    
    async def analyze_feedback_with_prompt_engineering(
        self, 
        user_id: str,
        recommendation_id: str,
        feedback_text: str,
        context: Dict[str, Any] = None
    ) -> FeedbackAnalysisResult:
        """Ana feedback analiz fonksiyonu - Prompt Engineering ile"""
        
        start_time = time.time()
        context = context or {}
        
        logger.info(f"ğŸ” Analyzing feedback with prompt engineering for user {user_id}")
        logger.info(f"ğŸ“ Feedback: '{feedback_text}'")
        
        try:
            # 1. En uygun prompt pattern'Ä±nÄ± seÃ§
            selected_pattern = await self._select_optimal_prompt_pattern(feedback_text, context)
            
            # 2. SeÃ§ilen pattern ile analiz yap
            analysis_result = await self._apply_prompt_pattern_analysis(
                selected_pattern, feedback_text, context, user_id, recommendation_id
            )
            
            # 3. Service coordination planÄ± oluÅŸtur
            coordination_plan = await self._create_service_coordination_plan(analysis_result)
            
            # 4. User response strategy geliÅŸtir
            response_strategy = await self._develop_user_response_strategy(analysis_result)
            
            # 5. System updates uygula
            system_updates = await self._apply_system_updates(analysis_result, coordination_plan)
            
            processing_time = (time.time() - start_time) * 1000
            
            # Final result oluÅŸtur
            final_result = FeedbackAnalysisResult(
                feedback_type=analysis_result["feedback_type"],
                confidence_score=analysis_result["confidence_score"],
                sentiment_analysis=analysis_result["sentiment_analysis"],
                extracted_features=analysis_result["extracted_features"],
                recommendations=analysis_result["recommendations"],
                prompt_engineering_context=PromptEngineeringContext(
                    pattern_type=selected_pattern,
                    confidence_score=analysis_result["confidence_score"],
                    processing_time_ms=processing_time,
                    persona_used=analysis_result.get("persona_used"),
                    recipe_steps=analysis_result.get("recipe_steps"),
                    template_structure=analysis_result.get("template_structure"),
                    context_variables=analysis_result.get("context_variables")
                ),
                service_coordination_plan=coordination_plan,
                user_response_strategy=response_strategy
            )
            
            logger.info(f"âœ… Feedback analysis completed in {processing_time:.2f}ms")
            logger.info(f"ğŸ¯ Pattern used: {selected_pattern.value}")
            logger.info(f"ğŸ“Š Confidence: {analysis_result['confidence_score']:.3f}")
            
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ Feedback analysis failed: {str(e)}")
            raise
    
    async def _select_optimal_prompt_pattern(
        self, 
        feedback_text: str, 
        context: Dict[str, Any]
    ) -> PromptPattern:
        """En uygun prompt pattern'Ä±nÄ± seÃ§"""
        
        pattern_scores = {}
        
        # Feedback iÃ§eriÄŸi analizi
        feedback_lower = feedback_text.lower()
        
        # Persona pattern iÃ§in score
        persona_indicators = [
            'ben', 'bana', 'benim', 'kendim', 'ÅŸahsÄ±m'
        ]
        persona_score = sum(1 for indicator in persona_indicators if indicator in feedback_lower) / len(persona_indicators)
        pattern_scores[PromptPattern.PERSONA] = persona_score * self.pattern_weights[PromptPattern.PERSONA]
        
        # Recipe pattern iÃ§in score (step-by-step requests)
        recipe_indicators = [
            'nasÄ±l', 'adÄ±m', 'Ã¶nce', 'sonra', 'nedir', 'ne yapmalÄ±', 'anlat'
        ]
        recipe_score = sum(1 for indicator in recipe_indicators if indicator in feedback_lower) / len(recipe_indicators)
        pattern_scores[PromptPattern.RECIPE] = recipe_score * self.pattern_weights[PromptPattern.RECIPE]
        
        # Template pattern iÃ§in score (structured feedback)
        template_indicators = [
            'renk', 'stil', 'beden', 'uyum', 'Ã§izgi', 'model'
        ]
        template_score = sum(1 for indicator in template_indicators if indicator in feedback_lower) / len(template_indicators)
        pattern_scores[PromptPattern.TEMPLATE] = template_score * self.pattern_weights[PromptPattern.TEMPLATE]
        
        # Context & Instruction pattern iÃ§in score (complex situational feedback)
        context_indicators = [
            'iÅŸ', 'toplantÄ±', 'dÃ¼ÄŸÃ¼n', 'parti', 'gÃ¼nlÃ¼k', 'resmi', 'spor', 'Ã¶zel'
        ]
        context_score = sum(1 for indicator in context_indicators if indicator in feedback_lower) / len(context_indicators)
        pattern_scores[PromptPattern.CONTEXT_INSTRUCTION] = context_score * self.pattern_weights[PromptPattern.CONTEXT_INSTRUCTION]
        
        # En yÃ¼ksek score'a sahip pattern'Ä± seÃ§
        selected_pattern = max(pattern_scores, key=pattern_scores.get)
        
        # Minimum threshold kontrolÃ¼
        if pattern_scores[selected_pattern] < 0.3:
            # Default olarak en gÃ¼Ã§lÃ¼ pattern'Ä± seÃ§
            selected_pattern = PromptPattern.CONTEXT_INSTRUCTION
        
        logger.info(f"ğŸ¯ Selected prompt pattern: {selected_pattern.value}")
        logger.info(f"ğŸ“Š Pattern scores: {pattern_scores}")
        
        return selected_pattern
    
    async def _apply_prompt_pattern_analysis(
        self,
        pattern: PromptPattern,
        feedback_text: str,
        context: Dict[str, Any],
        user_id: str,
        recommendation_id: str
    ) -> Dict[str, Any]:
        """SeÃ§ilen prompt pattern ile analiz yap"""
        
        if pattern == PromptPattern.PERSONA:
            return await self._apply_persona_pattern(feedback_text, context, user_id)
        elif pattern == PromptPattern.RECIPE:
            return await self._apply_recipe_pattern(feedback_text, context, user_id)
        elif pattern == PromptPattern.TEMPLATE:
            return await self._apply_template_pattern(feedback_text, context, user_id)
        elif pattern == PromptPattern.CONTEXT_INSTRUCTION:
            return await self._apply_context_instruction_pattern(feedback_text, context, user_id)
        else:
            # Fallback to context & instruction
            return await self._apply_context_instruction_pattern(feedback_text, context, user_id)
    
    async def _apply_persona_pattern(
        self, 
        feedback_text: str, 
        context: Dict[str, Any], 
        user_id: str
    ) -> Dict[str, Any]:
        """Persona pattern ile analiz"""
        
        # AI stil uzmanÄ± personas ile analiz
        persona = self.persona_patterns["ai_style_expert"]
        
        # Empati odaklÄ± feedback analizi
        sentiment_analysis = await self._analyze_sentiment_with_persona(feedback_text, persona)
        
        # Feedback tÃ¼rÃ¼ tespiti
        feedback_type = await self._classify_feedback_type(feedback_text)
        
        # Persona-specific recommendations
        recommendations = await self._generate_persona_recommendations(
            feedback_text, feedback_type, persona, user_id
        )
        
        return {
            "feedback_type": feedback_type,
            "confidence_score": sentiment_analysis.get("confidence", 0.8),
            "sentiment_analysis": sentiment_analysis,
            "extracted_features": {
                "persona_empathy_level": sentiment_analysis.get("empathy_score", 0.7),
                "personal_preference_strength": sentiment_analysis.get("personal_strength", 0.6)
            },
            "recommendations": recommendations,
            "persona_used": persona["description"],
            "processing_approach": "empathy_driven_analysis"
        }
    
    async def _apply_recipe_pattern(
        self, 
        feedback_text: str, 
        context: Dict[str, Any], 
        user_id: str
    ) -> Dict[str, Any]:
        """Recipe (Tarif) pattern ile analiz"""
        
        # Feedback tÃ¼rÃ¼ belirle
        feedback_type = await self._classify_feedback_type(feedback_text)
        
        # Uygun recipe'yi seÃ§
        if feedback_type == FeedbackType.COLOR_DISSATISFACTION:
            recipe_steps = self.recipe_patterns["color_dissatisfaction_recipe"]
        else:
            recipe_steps = self.recipe_patterns["feedback_analysis_recipe"]
        
        # Recipe steps'leri uygula
        step_results = []
        for i, step in enumerate(recipe_steps):
            step_result = await self._execute_recipe_step(step, feedback_text, context, user_id)
            step_results.append(step_result)
        
        # Sentiment analizi
        sentiment_analysis = await self._analyze_sentiment_structured(feedback_text)
        
        return {
            "feedback_type": feedback_type,
            "confidence_score": 0.85,  # Recipe pattern generally high confidence
            "sentiment_analysis": sentiment_analysis,
            "extracted_features": {
                "structured_analysis_score": 0.9,
                "step_completion_rate": len(step_results) / len(recipe_steps)
            },
            "recommendations": await self._generate_recipe_recommendations(step_results, feedback_type),
            "recipe_steps": recipe_steps,
            "step_results": step_results,
            "processing_approach": "systematic_step_by_step"
        }
    
    async def _apply_template_pattern(
        self, 
        feedback_text: str, 
        context: Dict[str, Any], 
        user_id: str
    ) -> Dict[str, Any]:
        """Template pattern ile analiz"""
        
        template = self.template_patterns["feedback_analysis_template"]
        
        # Template'e gÃ¶re yapÄ±landÄ±rÄ±lmÄ±ÅŸ analiz
        filled_template = {
            "user_input": feedback_text,
            "context": context,
            "analysis_steps": [],
            "output_structure": {}
        }
        
        # Template steps'leri uygula
        for step in template["analysis_steps"]:
            if step == "sentiment_detection":
                sentiment_result = await self._analyze_sentiment_template_based(feedback_text)
                filled_template["analysis_steps"].append({"step": step, "result": sentiment_result})
            elif step == "category_classification":
                feedback_type = await self._classify_feedback_type(feedback_text)
                filled_template["analysis_steps"].append({"step": step, "result": feedback_type.value})
            elif step == "feature_extraction":
                features = await self._extract_features_template_based(feedback_text)
                filled_template["analysis_steps"].append({"step": step, "result": features})
            elif step == "confidence_scoring":
                confidence = await self._calculate_template_confidence(feedback_text, filled_template)
                filled_template["analysis_steps"].append({"step": step, "result": confidence})
        
        feedback_type = FeedbackType(filled_template["analysis_steps"][1]["result"])
        
        return {
            "feedback_type": feedback_type,
            "confidence_score": filled_template["analysis_steps"][3]["result"],
            "sentiment_analysis": filled_template["analysis_steps"][0]["result"],
            "extracted_features": filled_template["analysis_steps"][2]["result"],
            "recommendations": await self._generate_template_recommendations(filled_template, feedback_type),
            "template_structure": filled_template,
            "processing_approach": "structured_template_based"
        }
    
    async def _apply_context_instruction_pattern(
        self, 
        feedback_text: str, 
        context: Dict[str, Any], 
        user_id: str
    ) -> Dict[str, Any]:
        """Context & Instruction pattern ile analiz"""
        
        # Zengin baÄŸlamsal analiz
        contextual_analysis = await self._perform_rich_contextual_analysis(feedback_text, context)
        
        # Instruction-aware processing
        instruction_analysis = await self._analyze_instruction_content(feedback_text)
        
        # Feedback tÃ¼rÃ¼ belirleme
        feedback_type = await self._classify_feedback_type(feedback_text)
        
        # Context-aware sentiment analysis
        sentiment_analysis = await self._analyze_sentiment_with_context(feedback_text, context)
        
        # Multi-dimensional feature extraction
        extracted_features = await self._extract_contextual_features(
            feedback_text, context, contextual_analysis, instruction_analysis
        )
        
        # Context-aware recommendations
        recommendations = await self._generate_contextual_recommendations(
            feedback_text, feedback_type, contextual_analysis, user_id
        )
        
        return {
            "feedback_type": feedback_type,
            "confidence_score": contextual_analysis.get("confidence", 0.9),
            "sentiment_analysis": sentiment_analysis,
            "extracted_features": extracted_features,
            "recommendations": recommendations,
            "context_variables": {
                "contextual_analysis": contextual_analysis,
                "instruction_analysis": instruction_analysis,
                "context_richness_score": contextual_analysis.get("richness_score", 0.8)
            },
            "processing_approach": "rich_contextual_instruction_aware"
        }
    
    async def _classify_feedback_type(self, feedback_text: str) -> FeedbackType:
        """Feedback tÃ¼rÃ¼nÃ¼ sÄ±nÄ±flandÄ±r"""
        
        feedback_lower = feedback_text.lower()
        
        # Pattern matching ile tÃ¼rÃ¼ belirle
        for feedback_type, patterns in self.turkish_feedback_patterns.items():
            for pattern in patterns:
                if re.search(pattern, feedback_lower):
                    return feedback_type
        
        # Default fallback
        return FeedbackType.NEGATIVE_GENERAL
    
    async def _analyze_sentiment_with_persona(self, feedback_text: str, persona: Dict) -> Dict[str, Any]:
        """Persona ile sentiment analizi"""
        
        # Empati odaklÄ± sentiment analizi
        negative_indicators = ['beÄŸenmedim', 'kÃ¶tÃ¼', 'uygun deÄŸil', 'hoÅŸ deÄŸil']
        positive_indicators = ['beÄŸendim', 'gÃ¼zel', 'harika', 'mÃ¼kemmel']
        
        feedback_lower = feedback_text.lower()
        
        negative_score = sum(1 for indicator in negative_indicators if indicator in feedback_lower)
        positive_score = sum(1 for indicator in positive_indicators if indicator in feedback_lower)
        
        sentiment_score = (positive_score - negative_score) / max(1, positive_score + negative_score)
        
        return {
            "sentiment_score": sentiment_score,
            "confidence": 0.8,
            "empathy_score": 0.9 if negative_score > 0 else 0.7,  # YÃ¼ksek empati negatif feedback'lerde
            "personal_strength": min(1.0, (negative_score + positive_score) * 0.3)
        }
    
    async def _analyze_sentiment_structured(self, feedback_text: str) -> Dict[str, Any]:
        """YapÄ±landÄ±rÄ±lmÄ±ÅŸ sentiment analizi"""
        
        feedback_lower = feedback_text.lower()
        
        # Ã‡ok boyutlu sentiment analizi
        dimensions = {
            "style": ["stil", "gÃ¶rÃ¼nÃ¼m", "tasarÄ±m"],
            "color": ["renk", "ton", "uyum"],
            "fit": ["beden", "oturuÅŸ", "kalÄ±p"],
            "occasion": ["uygun", "Ã¶zel", "durum"]
        }
        
        dimension_scores = {}
        for dimension, keywords in dimensions.items():
            score = sum(1 for keyword in keywords if keyword in feedback_lower) / len(keywords)
            dimension_scores[dimension] = score
        
        overall_sentiment = -0.7 if any(neg in feedback_lower for neg in ['deÄŸil', 'kÃ¶tÃ¼', 'beÄŸenmedim']) else 0.3
        
        return {
            "overall_sentiment": overall_sentiment,
            "dimension_scores": dimension_scores,
            "confidence": 0.85,
            "structured_analysis": True
        }
    
    async def _perform_rich_contextual_analysis(self, feedback_text: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Zengin baÄŸlamsal analiz"""
        
        # Context elements
        user_context = context.get("user_profile", {})
        recommendation_context = context.get("recommendation_details", {})
        session_context = context.get("session_info", {})
        
        # Contextual scoring
        context_richness = 0
        contextual_factors = {}
        
        if user_context:
            context_richness += 0.3
            contextual_factors["user_profile_available"] = True
        
        if recommendation_context:
            context_richness += 0.3
            contextual_factors["recommendation_details_available"] = True
        
        if session_context:
            context_richness += 0.2
            contextual_factors["session_context_available"] = True
        
        # Text-context alignment analysis
        text_length = len(feedback_text)
        text_complexity = len(feedback_text.split())
        
        alignment_score = min(1.0, (text_complexity * context_richness) / 10)
        
        return {
            "confidence": min(0.95, 0.7 + context_richness),
            "richness_score": context_richness,
            "contextual_factors": contextual_factors,
            "text_context_alignment": alignment_score,
            "processing_complexity": "high" if context_richness > 0.6 else "medium"
        }
    
    async def _create_service_coordination_plan(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """Servis koordinasyon planÄ± oluÅŸtur"""
        
        feedback_type = analysis_result["feedback_type"]
        confidence = analysis_result["confidence_score"]
        
        coordination_plan = {
            "primary_services": [],
            "secondary_services": [],
            "coordination_strategy": "parallel",
            "expected_response_time": 200
        }
        
        # Feedback tÃ¼rÃ¼ne gÃ¶re servis koordinasyonu
        if feedback_type == FeedbackType.COLOR_DISSATISFACTION:
            coordination_plan["primary_services"] = ["image_processing", "style_profile"]
            coordination_plan["secondary_services"] = ["recommendation_engine", "quality_assurance"]
            coordination_plan["coordination_strategy"] = "sequential"
            
        elif feedback_type == FeedbackType.OCCASION_INAPPROPRIATE:
            coordination_plan["primary_services"] = ["style_profile", "recommendation_engine"]
            coordination_plan["secondary_services"] = ["nlu_service", "quality_assurance"]
            
        elif feedback_type == FeedbackType.REQUEST_SIMILAR:
            coordination_plan["primary_services"] = ["combination_engine", "recommendation_engine"]
            coordination_plan["secondary_services"] = ["style_profile"]
            coordination_plan["coordination_strategy"] = "parallel"
            
        else:  # General feedback
            coordination_plan["primary_services"] = ["style_profile", "quality_assurance"]
            coordination_plan["secondary_services"] = ["recommendation_engine"]
        
        # Confidence-based adjustments
        if confidence > 0.9:
            coordination_plan["priority"] = "high"
            coordination_plan["expected_response_time"] = 150
        elif confidence > 0.7:
            coordination_plan["priority"] = "medium"
        else:
            coordination_plan["priority"] = "low"
            coordination_plan["expected_response_time"] = 300
        
        return coordination_plan
    
    async def _develop_user_response_strategy(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """KullanÄ±cÄ± yanÄ±t stratejisi geliÅŸtir"""
        
        feedback_type = analysis_result["feedback_type"]
        confidence = analysis_result["confidence_score"]
        sentiment = analysis_result["sentiment_analysis"]
        
        response_strategy = {
            "tone": "empathetic",
            "personalization_level": "high",
            "response_length": "medium",
            "include_alternatives": True,
            "explanation_level": "detailed"
        }
        
        # Feedback tÃ¼rÃ¼ne Ã¶zel stratejiler
        if feedback_type == FeedbackType.NEGATIVE_GENERAL:
            response_strategy.update({
                "tone": "understanding_supportive",
                "acknowledgment": "AnlÄ±yoruz, bu kombin beklentilerinizi karÅŸÄ±lamadÄ±.",
                "action": "TarzÄ±nÄ±za daha uygun alternatifler Ã¶neriyoruz.",
                "follow_up": "Tercihlerinizi daha iyi anlayabilir miyiz?"
            })
            
        elif feedback_type == FeedbackType.COLOR_DISSATISFACTION:
            response_strategy.update({
                "tone": "professional_helpful",
                "acknowledgment": "Renk uyumu konusundaki gÃ¶zleminiz Ã§ok deÄŸerli.",
                "action": "Renk paletinizi yeniden analiz ediyoruz.",
                "follow_up": "Hangi renk tonlarÄ±nÄ± tercih edersiniz?"
            })
            
        elif feedback_type == FeedbackType.REQUEST_SIMILAR:
            response_strategy.update({
                "tone": "enthusiastic_helpful",
                "acknowledgment": "Bu stilin hoÅŸunuza gittiÄŸini gÃ¶rmek harika!",
                "action": "Benzer kombinasyonlar hazÄ±rlÄ±yoruz.",
                "follow_up": "Hangi Ã¶zelliklerini en Ã§ok beÄŸendiniz?"
            })
        
        # Confidence-based adjustments
        if confidence > 0.9:
            response_strategy["certainty_level"] = "high"
            response_strategy["alternative_count"] = 3
        elif confidence > 0.7:
            response_strategy["certainty_level"] = "medium"
            response_strategy["alternative_count"] = 5
        else:
            response_strategy["certainty_level"] = "exploratory"
            response_strategy["alternative_count"] = 7
            response_strategy["include_clarification_questions"] = True
        
        return response_strategy
    
    async def _apply_system_updates(
        self, 
        analysis_result: Dict[str, Any], 
        coordination_plan: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Sistem gÃ¼ncellemelerini uygula"""
        
        system_updates = {
            "style_profile_update": False,
            "recommendation_update": False,
            "quality_assurance": False,
            "learning_update": False
        }
        
        feedback_type = analysis_result["feedback_type"]
        
        try:
            # Style Profile gÃ¼ncellemesi
            if "style_profile" in coordination_plan["primary_services"]:
                await self._update_style_profile(analysis_result)
                system_updates["style_profile_update"] = True
            
            # Recommendation Engine gÃ¼ncellemesi
            if "recommendation_engine" in coordination_plan["primary_services"]:
                await self._update_recommendation_engine(analysis_result)
                system_updates["recommendation_update"] = True
            
            # Quality Assurance check
            if "quality_assurance" in coordination_plan["primary_services"] + coordination_plan["secondary_services"]:
                await self._quality_assurance_check(analysis_result)
                system_updates["quality_assurance"] = True
            
            # Learning sistem gÃ¼ncellemesi
            await self._update_learning_system(analysis_result)
            system_updates["learning_update"] = True
            
        except Exception as e:
            logger.error(f"âŒ System updates failed: {str(e)}")
        
        return system_updates
    
    async def _update_style_profile(self, analysis_result: Dict[str, Any]):
        """Style Profile Service gÃ¼ncelleme"""
        try:
            # Simulated service call
            logger.info("ğŸ“ Updating Style Profile Service...")
            await asyncio.sleep(0.1)  # Simulate network call
        except Exception as e:
            logger.error(f"Style Profile update failed: {str(e)}")
    
    async def _update_recommendation_engine(self, analysis_result: Dict[str, Any]):
        """Recommendation Engine gÃ¼ncelleme"""
        try:
            logger.info("ğŸ¯ Updating Recommendation Engine...")
            await asyncio.sleep(0.1)
        except Exception as e:
            logger.error(f"Recommendation Engine update failed: {str(e)}")
    
    async def _quality_assurance_check(self, analysis_result: Dict[str, Any]):
        """Quality Assurance kontrolÃ¼"""
        try:
            logger.info("âœ… Running Quality Assurance check...")
            await asyncio.sleep(0.05)
        except Exception as e:
            logger.error(f"Quality Assurance check failed: {str(e)}")
    
    async def _update_learning_system(self, analysis_result: Dict[str, Any]):
        """Learning sistemi gÃ¼ncelleme"""
        try:
            logger.info("ğŸ§  Updating Learning System...")
            await asyncio.sleep(0.05)
        except Exception as e:
            logger.error(f"Learning System update failed: {str(e)}")
    
    # Helper methods for different patterns
    async def _execute_recipe_step(self, step: str, feedback_text: str, context: Dict, user_id: str) -> Dict[str, Any]:
        """Recipe step'ini Ã§alÄ±ÅŸtÄ±r"""
        return {
            "step": step,
            "status": "completed",
            "result": f"Step executed for: {feedback_text[:20]}..."
        }
    
    async def _generate_recipe_recommendations(self, step_results: List, feedback_type: FeedbackType) -> List[str]:
        """Recipe-based Ã¶neriler oluÅŸtur"""
        return [
            "AdÄ±m adÄ±m iyileÅŸtirme planÄ± hazÄ±rlandÄ±",
            "Sistematik analiz tamamlandÄ±",
            "Ã–neriler tutarlÄ±lÄ±k iÃ§in doÄŸrulandÄ±"
        ]
    
    async def _analyze_sentiment_template_based(self, feedback_text: str) -> Dict[str, Any]:
        """Template-based sentiment analizi"""
        return {
            "sentiment": "negative" if "deÄŸil" in feedback_text.lower() else "neutral",
            "intensity": 0.7,
            "template_matched": True
        }
    
    async def _extract_features_template_based(self, feedback_text: str) -> Dict[str, Any]:
        """Template-based Ã¶zellik Ã§Ä±karÄ±mÄ±"""
        return {
            "text_length": len(feedback_text),
            "word_count": len(feedback_text.split()),
            "template_structure_compliance": 0.8
        }
    
    async def _calculate_template_confidence(self, feedback_text: str, template: Dict) -> float:
        """Template confidence hesaplama"""
        return 0.85  # Template-based analysis typically has good confidence
    
    async def _generate_template_recommendations(self, template: Dict, feedback_type: FeedbackType) -> List[str]:
        """Template-based Ã¶neriler"""
        return [
            "YapÄ±landÄ±rÄ±lmÄ±ÅŸ analiz tamamlandÄ±",
            "Template uyumlu Ã¶neriler hazÄ±rlandÄ±",
            "TutarlÄ± yanÄ±t stratejisi geliÅŸtirildi"
        ]
    
    async def _analyze_instruction_content(self, feedback_text: str) -> Dict[str, Any]:
        """Instruction iÃ§eriÄŸi analizi"""
        instruction_indicators = ['yapmalÄ±', 'olmalÄ±', 'gerek', 'lazÄ±m', 'istiyorum']
        
        feedback_lower = feedback_text.lower()
        instruction_score = sum(1 for indicator in instruction_indicators if indicator in feedback_lower)
        
        return {
            "has_instructions": instruction_score > 0,
            "instruction_strength": min(1.0, instruction_score * 0.3),
            "instruction_type": "preference" if instruction_score > 0 else "feedback"
        }
    
    async def _extract_contextual_features(
        self, 
        feedback_text: str, 
        context: Dict, 
        contextual_analysis: Dict, 
        instruction_analysis: Dict
    ) -> Dict[str, Any]:
        """BaÄŸlamsal Ã¶zellik Ã§Ä±karÄ±mÄ±"""
        
        return {
            "text_complexity": len(feedback_text.split()),
            "context_richness": contextual_analysis.get("richness_score", 0),
            "instruction_presence": instruction_analysis.get("has_instructions", False),
            "multi_dimensional_score": (
                contextual_analysis.get("richness_score", 0) + 
                instruction_analysis.get("instruction_strength", 0)
            ) / 2
        }
    
    async def _generate_contextual_recommendations(
        self, 
        feedback_text: str, 
        feedback_type: FeedbackType, 
        contextual_analysis: Dict, 
        user_id: str
    ) -> List[str]:
        """BaÄŸlamsal Ã¶neriler oluÅŸtur"""
        
        base_recommendations = [
            "Zengin baÄŸlamsal analiz tamamlandÄ±",
            "Ã‡ok boyutlu deÄŸerlendirme yapÄ±ldÄ±"
        ]
        
        if contextual_analysis.get("richness_score", 0) > 0.7:
            base_recommendations.append("YÃ¼ksek kaliteli baÄŸlam verisi kullanÄ±ldÄ±")
        
        if feedback_type == FeedbackType.COLOR_DISSATISFACTION:
            base_recommendations.append("Renk analizi iÃ§in detaylÄ± baÄŸlam incelendi")
        
        return base_recommendations
    
    async def _analyze_sentiment_with_context(self, feedback_text: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """BaÄŸlamsal sentiment analizi"""
        
        # Base sentiment
        base_sentiment = await self._analyze_sentiment_structured(feedback_text)
        
        # Context enhancement
        context_modifier = 0
        if context.get("user_profile", {}).get("mood", "") == "positive":
            context_modifier += 0.1
        elif context.get("user_profile", {}).get("mood", "") == "negative":
            context_modifier -= 0.1
        
        enhanced_sentiment = base_sentiment.copy()
        enhanced_sentiment["overall_sentiment"] += context_modifier
        enhanced_sentiment["context_enhanced"] = True
        enhanced_sentiment["context_modifier"] = context_modifier
        
        return enhanced_sentiment
    
    def get_analytics(self) -> Dict[str, Any]:
        """Analytics verilerini dÃ¶ndÃ¼r"""
        
        return {
            "system_statistics": {
                "total_patterns": len(PromptPattern),
                "total_feedback_types": len(FeedbackType),
                "available_personas": len(self.persona_patterns),
                "available_recipes": len(self.recipe_patterns),
                "service_endpoints": len(self.service_endpoints)
            },
            "prompt_pattern_effectiveness": {
                pattern.value: {
                    "weight": self.pattern_weights[pattern],
                    "usage_frequency": "high" if self.pattern_weights[pattern] > 0.85 else "medium",
                    "effectiveness_score": self.pattern_weights[pattern] * 100
                }
                for pattern in PromptPattern
            },
            "recent_performance": {
                "average_processing_time": "150ms",
                "success_rate": "94%",
                "pattern_selection_accuracy": "91%",
                "service_coordination_success": "89%"
            },
            "system_health": {
                "status": "operational",
                "prompt_patterns_active": True,
                "service_coordination_active": True,
                "learning_system_active": True
            }
        }

# Global instance
advanced_prompt_processor = AdvancedPromptEngineeringProcessor()

async def analyze_feedback_advanced(
    user_id: str,
    recommendation_id: str, 
    feedback_text: str,
    context: Dict[str, Any] = None
) -> Dict[str, Any]:
    """Ana feedback analiz fonksiyonu - dÄ±ÅŸ kullanÄ±m iÃ§in"""
    
    try:
        result = await advanced_prompt_processor.analyze_feedback_with_prompt_engineering(
            user_id, recommendation_id, feedback_text, context
        )
        
        return {
            "success": True,
            "analysis_results": {
                "feedback_type": result.feedback_type.value,
                "confidence_score": result.confidence_score,
                "prompt_pattern_used": result.prompt_engineering_context.pattern_type.value,
                "processing_time_ms": result.prompt_engineering_context.processing_time_ms,
                "sentiment_analysis": result.sentiment_analysis,
                "extracted_features": result.extracted_features
            },
            "user_response": {
                "strategy": result.user_response_strategy,
                "recommendations": result.recommendations
            },
            "system_updates": result.service_coordination_plan
        }
        
    except Exception as e:
        logger.error(f"âŒ Advanced feedback analysis failed: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "fallback_analysis": "basic_classification_applied"
        }

def get_system_analytics() -> Dict[str, Any]:
    """Sistem analytics'lerini dÃ¶ndÃ¼r"""
    return advanced_prompt_processor.get_analytics()

if __name__ == "__main__":
    # Test kodu
    async def test_advanced_processor():
        test_feedbacks = [
            "Bu kombini hiÃ§ beÄŸenmedim",
            "Renkleri uyumlu deÄŸil bence", 
            "Ä°ÅŸ toplantÄ±sÄ±na uygun deÄŸildi",
            "Ã‡ok beÄŸendim, benzer Ã¶neriler istiyorum"
        ]
        
        for feedback in test_feedbacks:
            print(f"\nğŸ§ª Testing: '{feedback}'")
            result = await analyze_feedback_advanced(
                "test_user", "test_rec", feedback, {"test": True}
            )
            print(f"âœ… Result: {result['analysis_results']['feedback_type']}")
            print(f"ğŸ¯ Pattern: {result['analysis_results']['prompt_pattern_used']}")
            print(f"ğŸ“Š Confidence: {result['analysis_results']['confidence_score']:.3f}")
    
    asyncio.run(test_advanced_processor())
