{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a76f032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanılacak Cihaz: cuda\n",
      "Veri Yükleyiciler hazır.\n",
      "Model özelleştirildi, son katman bloğu çözüldü ve cihaza taşındı.\n",
      "\n",
      "--- GELİŞMİŞ EĞİTİM BAŞLIYOR ---\n",
      "Epoch 1/10 | Eğitim Loss: 0.4638 Acc: 0.8279 | Doğrulama Loss: 0.2240 Acc: 0.9058\n",
      "** Modelin daha iyi bir versiyonu kaydedildi (Doğrulama Acc: 0.9058) **\n",
      "Epoch 2/10 | Eğitim Loss: 0.2661 Acc: 0.8967 | Doğrulama Loss: 0.1884 Acc: 0.9283\n",
      "** Modelin daha iyi bir versiyonu kaydedildi (Doğrulama Acc: 0.9283) **\n",
      "Epoch 3/10 | Eğitim Loss: 0.2241 Acc: 0.9140 | Doğrulama Loss: 0.1819 Acc: 0.9277\n",
      "Epoch 4/10 | Eğitim Loss: 0.1852 Acc: 0.9273 | Doğrulama Loss: 0.1560 Acc: 0.9380\n",
      "** Modelin daha iyi bir versiyonu kaydedildi (Doğrulama Acc: 0.9380) **\n",
      "Epoch 5/10 | Eğitim Loss: 0.1696 Acc: 0.9329 | Doğrulama Loss: 0.1573 Acc: 0.9387\n",
      "** Modelin daha iyi bir versiyonu kaydedildi (Doğrulama Acc: 0.9387) **\n",
      "Epoch 6/10 | Eğitim Loss: 0.1684 Acc: 0.9329 | Doğrulama Loss: 0.1554 Acc: 0.9413\n",
      "** Modelin daha iyi bir versiyonu kaydedildi (Doğrulama Acc: 0.9413) **\n",
      "Epoch 7/10 | Eğitim Loss: 0.1632 Acc: 0.9361 | Doğrulama Loss: 0.1528 Acc: 0.9409\n",
      "Epoch 8/10 | Eğitim Loss: 0.1614 Acc: 0.9364 | Doğrulama Loss: 0.1545 Acc: 0.9409\n",
      "Epoch 9/10 | Eğitim Loss: 0.1627 Acc: 0.9372 | Doğrulama Loss: 0.1520 Acc: 0.9417\n",
      "** Modelin daha iyi bir versiyonu kaydedildi (Doğrulama Acc: 0.9417) **\n",
      "Epoch 10/10 | Eğitim Loss: 0.1618 Acc: 0.9374 | Doğrulama Loss: 0.1520 Acc: 0.9425\n",
      "** Modelin daha iyi bir versiyonu kaydedildi (Doğrulama Acc: 0.9425) **\n",
      "\n",
      "--- EĞİTİM TAMAMLANDI ---\n",
      "Toplam Eğitim Süresi: 107 dakika 40 saniye\n",
      "En iyi model 'models/best_model_advanced.pth' olarak kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# AURA AI ENGINE - ADIM 4 (GELİŞMİŞ): DERİNLEMESİNE İNCE AYAR\n",
    "# ==============================================================================\n",
    "# AMAÇ: Modelin son katmanlarını da eğitime dahil ederek ve öğrenme oranı\n",
    "#       zamanlaması kullanarak modelin performansını artırmak.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# --- ADIM 1: Gerekli Kütüphanelerin Yüklenmesi ve Parametrelerin Ayarlanması ---\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# YENİ: Zamanlayıcı için import eklendi\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# -- Ayarlar --\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "# Daha derin bir eğitim için epoch sayısını 10'da tutuyoruz.\n",
    "NUM_EPOCHS = 10\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Veri yolları (Notebook için '../' kullanılır, .py scripti için kaldırılır)\n",
    "PROCESSED_DATA_PATH = os.path.join(\"..\", \"data\", \"processed\")\n",
    "IMAGES_PATH = os.path.join(\"..\", \"data\", \"raw\", \"images\")\n",
    "MODEL_SAVE_PATH = os.path.join(\"..\", \"models\")\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Kullanılacak Cihaz: {device}\")\n",
    "\n",
    "\n",
    "# --- ADIM 2: Özel Veri Seti Sınıfı (Değişiklik Yok) ---\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.classes = self.annotations['articleType'].astype('category').cat.categories\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.annotations['label'] = self.annotations['articleType'].apply(lambda x: self.class_to_idx[x])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.annotations.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.image_dir, str(img_id) + \".jpg\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = torch.tensor(self.annotations.iloc[idx, -1], dtype=torch.long)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "\n",
    "# --- ADIM 3: Veri Dönüşümleri ve Yükleyiciler (Değişiklik Yok, Güçlü Augmentation Kalıyor) ---\n",
    "\n",
    "data_transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2))\n",
    "])\n",
    "\n",
    "data_transforms_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = FashionDataset(csv_file=os.path.join(PROCESSED_DATA_PATH, \"train_cleaned.csv\"),\n",
    "                               image_dir=IMAGES_PATH,\n",
    "                               transform=data_transforms_train)\n",
    "\n",
    "val_dataset = FashionDataset(csv_file=os.path.join(PROCESSED_DATA_PATH, \"validation_cleaned.csv\"),\n",
    "                             image_dir=IMAGES_PATH,\n",
    "                             transform=data_transforms_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "print(\"Veri Yükleyiciler hazır.\")\n",
    "\n",
    "\n",
    "# --- ADIM 4: Modelin Özelleştirilmesi (YENİ - Katmanlar Çözüldü) ---\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# YENİ: Son konvolüsyonel bloğun (layer4) parametrelerini çözüyoruz.\n",
    "# Artık bu katman da eğitim sırasında güncellenecek.\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, NUM_CLASSES) # Bu katmanın requires_grad'ı zaten True\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Model özelleştirildi, son katman bloğu çözüldü ve cihaza taşındı.\")\n",
    "\n",
    "\n",
    "# --- ADIM 5: Loss Fonksiyonu, Optimizer ve Zamanlayıcı (YENİ) ---\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# YENİ: Optimizer'ı iki farklı parametre grubunu, farklı öğrenme oranlarıyla\n",
    "# güncelleyecek şekilde tanımlıyoruz.\n",
    "params_to_update = [\n",
    "    # Yeni eklediğimiz fc katmanı daha hızlı öğrenmeli\n",
    "    {'params': model.fc.parameters(), 'lr': LEARNING_RATE},\n",
    "    # Çözdüğümüz layer4 ise daha yavaş öğrenerek eski bilgilerini korumalı\n",
    "    {'params': model.layer4.parameters(), 'lr': LEARNING_RATE / 10}\n",
    "]\n",
    "optimizer = optim.Adam(params_to_update)\n",
    "\n",
    "# YENİ: Öğrenme oranı zamanlayıcısını tanımlıyoruz.\n",
    "# Her 3 epoch'ta bir, öğrenme oranını 0.1 ile çarpacak (yani 10'a bölecek).\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "\n",
    "# --- ADIM 6: Eğitim ve Doğrulama Döngüsü (YENİ - scheduler.step() eklendi) ---\n",
    "\n",
    "print(\"\\n--- GELİŞMİŞ EĞİTİM BAŞLIYOR ---\")\n",
    "start_time = time.time()\n",
    "best_val_acc = 0.0 # En iyi modeli doğruluk oranına göre seçeceğiz\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    # ... (Eğitim ve Doğrulama aşamaları aynı kalıyor) ...\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "    val_loss = val_loss / len(val_dataset)\n",
    "    val_acc = val_corrects.double() / len(val_dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
    "          f\"Eğitim Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} | \"\n",
    "          f\"Doğrulama Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # YENİ: Her epoch'un sonunda zamanlayıcıyı güncelliyoruz.\n",
    "    scheduler.step()\n",
    "    \n",
    "    # En iyi modeli doğruluk oranına (accuracy) göre kaydet\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_SAVE_PATH, \"best_model_advanced.pth\"))\n",
    "        print(f\"** Modelin daha iyi bir versiyonu kaydedildi (Doğrulama Acc: {best_val_acc:.4f}) **\")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"\\n--- EĞİTİM TAMAMLANDI ---\")\n",
    "print(f\"Toplam Eğitim Süresi: {training_time // 60:.0f} dakika {training_time % 60:.0f} saniye\")\n",
    "print(f\"En iyi model 'models/best_model_advanced.pth' olarak kaydedildi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aura_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
