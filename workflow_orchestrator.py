# ğŸš€ AURA AI - WORKFLOW ORCHESTRATION ENGINE (PHASE 7)
# Bu modÃ¼l, tÃ¼m mikroservisleri koordine eden akÄ±llÄ± iÅŸ akÄ±ÅŸÄ± motoru saÄŸlar
# End-to-end fashion AI pipeline'larÄ± ile gerÃ§ek zamanlÄ± orkestrasyon yapar

# asyncio - asenkron programlama iÃ§in temel kÃ¼tÃ¼phane
import asyncio
# aiohttp - asenkron HTTP client iÅŸlemleri iÃ§in
import aiohttp
# json - JSON veri iÅŸleme iÃ§in
import json
# datetime - zaman damgasÄ± ve sÃ¼re hesaplamalarÄ± iÃ§in
from datetime import datetime, timedelta
# typing - type hints iÃ§in
from typing import Dict, List, Any, Optional, Callable
# dataclasses - veri yapÄ±larÄ± iÃ§in
from dataclasses import dataclass, field
# enum - sabitler iÃ§in
from enum import Enum
# logging - hata ayÄ±klama ve izleme iÃ§in
import logging
# uuid - benzersiz kimlik oluÅŸturma iÃ§in
import uuid
# time - performans Ã¶lÃ§Ã¼mÃ¼ iÃ§in
import time
# traceback - hata izleme iÃ§in
import traceback

# Logging konfigÃ¼rasyonu - detaylÄ± izleme iÃ§in
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class WorkflowStatus(Enum):
    """
    Ä°ÅŸ akÄ±ÅŸÄ± durumlarÄ± enum sÄ±nÄ±fÄ±.
    Her iÅŸ akÄ±ÅŸÄ±nÄ±n mevcut durumunu takip etmek iÃ§in kullanÄ±lÄ±r.
    """
    PENDING = "pending"          # Beklemede - henÃ¼z baÅŸlamadÄ±
    RUNNING = "running"          # Ã‡alÄ±ÅŸÄ±yor - aktif olarak iÅŸleniyor
    COMPLETED = "completed"      # TamamlandÄ± - baÅŸarÄ±yla bitti
    FAILED = "failed"           # BaÅŸarÄ±sÄ±z - hata ile durdu
    CANCELLED = "cancelled"      # Ä°ptal edildi - kullanÄ±cÄ± tarafÄ±ndan durduruldu
    RETRYING = "retrying"       # Yeniden deniyor - hata sonrasÄ± tekrar

class ServiceType(Enum):
    """
    Mikroservis tipleri enum sÄ±nÄ±fÄ±.
    Her servisin tipini ve Ã¶zelliklerini tanÄ±mlar.
    """
    IMAGE_PROCESSING = "image_processing"        # GÃ¶rÃ¼ntÃ¼ iÅŸleme servisi
    NLU = "nlu"                                 # DoÄŸal dil anlama servisi
    STYLE_PROFILE = "style_profile"             # Stil profil servisi
    COMBINATION_ENGINE = "combination_engine"    # Kombinasyon motor servisi
    RECOMMENDATION_ENGINE = "recommendation_engine"  # Ã–neri motor servisi

@dataclass
class WorkflowStep:
    """
    Tek bir iÅŸ akÄ±ÅŸÄ± adÄ±mÄ±nÄ± temsil eden veri sÄ±nÄ±fÄ±.
    Her adÄ±m bir mikroservise karÅŸÄ±lÄ±k gelir ve baÄŸÄ±mlÄ±lÄ±klarÄ± vardÄ±r.
    """
    step_id: str                    # AdÄ±m benzersiz kimliÄŸi
    service_type: ServiceType       # Hangi mikroservise karÅŸÄ±lÄ±k geldiÄŸi
    endpoint: str                   # Servisin Ã§aÄŸrÄ±lacak endpoint'i
    dependencies: List[str] = field(default_factory=list)  # Ã–nce tamamlanmasÄ± gereken adÄ±mlar
    timeout: float = 30.0           # Maximum bekleme sÃ¼resi (saniye)
    retry_count: int = 3            # Hata durumunda kaÃ§ kez yeniden denenecek
    required: bool = True           # Bu adÄ±m zorunlu mu yoksa opsiyonel mi
    fallback_enabled: bool = True   # Hata durumunda fallback mekanizmasÄ± var mÄ±

@dataclass
class WorkflowDefinition:
    """
    Tam bir iÅŸ akÄ±ÅŸÄ± tanÄ±mÄ±nÄ± iÃ§eren veri sÄ±nÄ±fÄ±.
    AdÄ±mlar, baÄŸÄ±mlÄ±lÄ±klar ve konfigÃ¼rasyon bilgilerini tutar.
    """
    workflow_id: str                # Ä°ÅŸ akÄ±ÅŸÄ± benzersiz kimliÄŸi
    name: str                      # Ä°ÅŸ akÄ±ÅŸÄ± aÃ§Ä±klayÄ±cÄ± ismi
    description: str               # DetaylÄ± aÃ§Ä±klama
    steps: List[WorkflowStep]      # Ä°ÅŸ akÄ±ÅŸÄ±nÄ± oluÅŸturan adÄ±mlar listesi
    max_execution_time: float = 300.0  # Maximum toplam Ã§alÄ±ÅŸma sÃ¼resi (saniye)
    parallel_execution: bool = True     # AdÄ±mlar paralel Ã§alÄ±ÅŸtÄ±rÄ±labilir mi
    error_policy: str = "continue"      # Hata durumunda politika: "stop", "continue", "retry"

@dataclass
class WorkflowContext:
    """
    Ä°ÅŸ akÄ±ÅŸÄ± Ã§alÄ±ÅŸma zamanÄ± baÄŸlam bilgilerini tutan sÄ±nÄ±f.
    KullanÄ±cÄ± verisi, geÃ§ici sonuÃ§lar ve metadata burada saklanÄ±r.
    """
    user_id: str                   # Ä°ÅŸ akÄ±ÅŸÄ±nÄ± baÅŸlatan kullanÄ±cÄ± kimliÄŸi
    session_id: str                # Oturum kimliÄŸi
    input_data: Dict[str, Any]     # BaÅŸlangÄ±Ã§ input verileri
    context_data: Dict[str, Any] = field(default_factory=dict)  # BaÄŸlamsal veriler
    step_results: Dict[str, Any] = field(default_factory=dict)  # Her adÄ±mÄ±n sonuÃ§larÄ±
    metadata: Dict[str, Any] = field(default_factory=dict)      # Ek metadata bilgileri

@dataclass
class WorkflowExecution:
    """
    Ã‡alÄ±ÅŸan bir iÅŸ akÄ±ÅŸÄ±nÄ±n durumunu ve sonuÃ§larÄ±nÄ± tutan sÄ±nÄ±f.
    Runtime bilgileri, performans metrikleri ve sonuÃ§larÄ± iÃ§erir.
    """
    execution_id: str              # Ã‡alÄ±ÅŸtÄ±rma benzersiz kimliÄŸi
    workflow_id: str               # Hangi iÅŸ akÄ±ÅŸÄ±nÄ±n Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±
    status: WorkflowStatus         # Mevcut durum
    context: WorkflowContext       # Ã‡alÄ±ÅŸma zamanÄ± baÄŸlamÄ±
    start_time: datetime           # BaÅŸlangÄ±Ã§ zamanÄ±
    end_time: Optional[datetime] = None         # BitiÅŸ zamanÄ±
    current_step: Optional[str] = None          # Åu an Ã§alÄ±ÅŸan adÄ±m
    completed_steps: List[str] = field(default_factory=list)  # Tamamlanan adÄ±mlar
    failed_steps: List[str] = field(default_factory=list)     # BaÅŸarÄ±sÄ±z adÄ±mlar
    error_messages: List[str] = field(default_factory=list)   # Hata mesajlarÄ±
    performance_metrics: Dict[str, Any] = field(default_factory=dict)  # Performans metrikleri

class AuraWorkflowOrchestrator:
    """
    Aura AI Workflow Orchestration Engine - Ana orkestrasyon motoru.
    
    Bu sÄ±nÄ±f tÃ¼m mikroservisleri koordine eder ve akÄ±llÄ± iÅŸ akÄ±ÅŸlarÄ± yÃ¶netir.
    End-to-end fashion AI pipeline'larÄ±nÄ± gerÃ§ek zamanlÄ± olarak Ã§alÄ±ÅŸtÄ±rÄ±r.
    """
    
    def __init__(self):
        # Mikroservis URL'lerini tanÄ±mla - her servisin base URL'si
        self.service_urls = {
            ServiceType.IMAGE_PROCESSING: "http://localhost:8001",
            ServiceType.NLU: "http://localhost:8002", 
            ServiceType.STYLE_PROFILE: "http://localhost:8003",
            ServiceType.COMBINATION_ENGINE: "http://localhost:8004",
            ServiceType.RECOMMENDATION_ENGINE: "http://localhost:8005"
        }
        
        # Ã–ntanÄ±mlÄ± iÅŸ akÄ±ÅŸÄ± ÅŸablonlarÄ±nÄ± yÃ¼kle
        self.workflow_definitions = {}
        self._initialize_standard_workflows()
        
        # Aktif Ã§alÄ±ÅŸan iÅŸ akÄ±ÅŸlarÄ±nÄ± takip et
        self.active_executions: Dict[str, WorkflowExecution] = {}
        
        # Circuit breaker pattern iÃ§in servis saÄŸlÄ±k durumlarÄ±
        self.service_health = {service: True for service in ServiceType}
        
        # Performans metrikleri iÃ§in sayaÃ§lar
        self.metrics = {
            "total_workflows": 0,           # Toplam Ã§alÄ±ÅŸtÄ±rÄ±lan iÅŸ akÄ±ÅŸÄ± sayÄ±sÄ±
            "successful_workflows": 0,      # BaÅŸarÄ±lÄ± iÅŸ akÄ±ÅŸÄ± sayÄ±sÄ±
            "failed_workflows": 0,          # BaÅŸarÄ±sÄ±z iÅŸ akÄ±ÅŸÄ± sayÄ±sÄ±
            "average_execution_time": 0.0,  # Ortalama Ã§alÄ±ÅŸma sÃ¼resi
            "service_call_count": {service: 0 for service in ServiceType},  # Her servise yapÄ±lan Ã§aÄŸrÄ± sayÄ±sÄ±
            "service_error_count": {service: 0 for service in ServiceType}  # Her serviste oluÅŸan hata sayÄ±sÄ±
        }
        
        logger.info("ğŸš€ Aura Workflow Orchestrator initialized successfully!")
    
    def _initialize_standard_workflows(self):
        """
        Standart iÅŸ akÄ±ÅŸÄ± ÅŸablonlarÄ±nÄ± baÅŸlat.
        En sÄ±k kullanÄ±lan fashion AI workflow'larÄ±nÄ± Ã¶ntanÄ±mlÄ± olarak oluÅŸturur.
        """
        
        # 1. Complete Fashion Analysis Workflow - Tam moda analizi
        complete_analysis_steps = [
            WorkflowStep(
                step_id="image_analysis",
                service_type=ServiceType.IMAGE_PROCESSING,
                endpoint="/analyze_image_advanced",
                dependencies=[],  # Ä°lk adÄ±m, baÄŸÄ±mlÄ±lÄ±k yok
                timeout=15.0,
                retry_count=2
            ),
            WorkflowStep(
                step_id="text_understanding", 
                service_type=ServiceType.NLU,
                endpoint="/analyze_text_advanced",
                dependencies=[],  # Paralel Ã§alÄ±ÅŸabilir
                timeout=10.0,
                retry_count=2
            ),
            WorkflowStep(
                step_id="style_profiling",
                service_type=ServiceType.STYLE_PROFILE,
                endpoint="/analyze_style_advanced",
                dependencies=["image_analysis", "text_understanding"],  # Her ikisine de baÄŸÄ±mlÄ±
                timeout=12.0,
                retry_count=2
            ),
            WorkflowStep(
                step_id="combination_generation",
                service_type=ServiceType.COMBINATION_ENGINE,
                endpoint="/generate_combination_advanced",
                dependencies=["style_profiling"],
                timeout=8.0,
                retry_count=2
            ),
            WorkflowStep(
                step_id="personalized_recommendations",
                service_type=ServiceType.RECOMMENDATION_ENGINE,
                endpoint="/recommendations_advanced",
                dependencies=["combination_generation"],
                timeout=10.0,
                retry_count=2
            )
        ]
        
        self.workflow_definitions["complete_fashion_analysis"] = WorkflowDefinition(
            workflow_id="complete_fashion_analysis",
            name="Complete Fashion Analysis",
            description="End-to-end fashion analysis: image â†’ style â†’ combinations â†’ recommendations",
            steps=complete_analysis_steps,
            max_execution_time=120.0,  # 2 dakika max
            parallel_execution=True,
            error_policy="continue"
        )
        
        # 2. Quick Style Assessment Workflow - HÄ±zlÄ± stil deÄŸerlendirmesi
        quick_style_steps = [
            WorkflowStep(
                step_id="quick_image_scan",
                service_type=ServiceType.IMAGE_PROCESSING,
                endpoint="/quick_analysis",
                timeout=5.0,
                retry_count=1
            ),
            WorkflowStep(
                step_id="style_classification",
                service_type=ServiceType.STYLE_PROFILE,
                endpoint="/classify_style",
                dependencies=["quick_image_scan"],
                timeout=3.0,
                retry_count=1
            ),
            WorkflowStep(
                step_id="instant_recommendations",
                service_type=ServiceType.RECOMMENDATION_ENGINE,
                endpoint="/quick_recommendations",
                dependencies=["style_classification"],
                timeout=4.0,
                retry_count=1
            )
        ]
        
        self.workflow_definitions["quick_style_assessment"] = WorkflowDefinition(
            workflow_id="quick_style_assessment",
            name="Quick Style Assessment",
            description="Fast style analysis for immediate recommendations",
            steps=quick_style_steps,
            max_execution_time=30.0,  # 30 saniye max
            parallel_execution=False,  # SÄ±ralÄ± Ã§alÄ±ÅŸsÄ±n, hÄ±z iÃ§in
            error_policy="stop"
        )
        
        # 3. User Onboarding Workflow - KullanÄ±cÄ± kayÄ±t sÃ¼reci
        onboarding_steps = [
            WorkflowStep(
                step_id="preference_analysis",
                service_type=ServiceType.NLU,
                endpoint="/analyze_preferences",
                timeout=8.0
            ),
            WorkflowStep(
                step_id="initial_profile_creation",
                service_type=ServiceType.STYLE_PROFILE,
                endpoint="/create_profile",
                dependencies=["preference_analysis"],
                timeout=10.0
            ),
            WorkflowStep(
                step_id="welcome_recommendations",
                service_type=ServiceType.RECOMMENDATION_ENGINE,
                endpoint="/welcome_recommendations",
                dependencies=["initial_profile_creation"],
                timeout=12.0
            )
        ]
        
        self.workflow_definitions["user_onboarding"] = WorkflowDefinition(
            workflow_id="user_onboarding",
            name="User Onboarding",
            description="New user onboarding with initial style profiling",
            steps=onboarding_steps,
            max_execution_time=60.0,
            parallel_execution=False,
            error_policy="retry"
        )
        
        logger.info(f"âœ… Initialized {len(self.workflow_definitions)} standard workflows")
    
    async def execute_workflow(self, workflow_id: str, context: WorkflowContext) -> WorkflowExecution:
        """
        Belirtilen iÅŸ akÄ±ÅŸÄ±nÄ± Ã§alÄ±ÅŸtÄ±r.
        
        Args:
            workflow_id: Ã‡alÄ±ÅŸtÄ±rÄ±lacak iÅŸ akÄ±ÅŸÄ±nÄ±n kimliÄŸi
            context: Ä°ÅŸ akÄ±ÅŸÄ± baÄŸlam bilgileri
            
        Returns:
            WorkflowExecution: Ã‡alÄ±ÅŸtÄ±rma durumu ve sonuÃ§larÄ±
        """
        
        # Ä°ÅŸ akÄ±ÅŸÄ± tanÄ±mÄ±nÄ± bul
        if workflow_id not in self.workflow_definitions:
            raise ValueError(f"Workflow '{workflow_id}' not found")
        
        workflow_def = self.workflow_definitions[workflow_id]
        
        # Yeni Ã§alÄ±ÅŸtÄ±rma instance'Ä± oluÅŸtur
        execution_id = str(uuid.uuid4())
        execution = WorkflowExecution(
            execution_id=execution_id,
            workflow_id=workflow_id,
            status=WorkflowStatus.PENDING,
            context=context,
            start_time=datetime.now()
        )
        
        # Aktif Ã§alÄ±ÅŸtÄ±rmalar listesine ekle
        self.active_executions[execution_id] = execution
        
        logger.info(f"ğŸš€ Starting workflow '{workflow_def.name}' (ID: {execution_id})")
        
        try:
            # Ä°ÅŸ akÄ±ÅŸÄ±nÄ± Ã§alÄ±ÅŸtÄ±r
            execution.status = WorkflowStatus.RUNNING
            await self._execute_workflow_steps(workflow_def, execution)
            
            # BaÅŸarÄ±yla tamamlandÄ±
            execution.status = WorkflowStatus.COMPLETED
            execution.end_time = datetime.now()
            
            # Metrikleri gÃ¼ncelle
            self._update_metrics(execution, success=True)
            
            logger.info(f"âœ… Workflow '{workflow_def.name}' completed successfully in {self._get_execution_duration(execution):.2f}s")
            
        except Exception as e:
            # Hata durumunda
            execution.status = WorkflowStatus.FAILED
            execution.end_time = datetime.now()
            execution.error_messages.append(str(e))
            
            # Metrikleri gÃ¼ncelle
            self._update_metrics(execution, success=False)
            
            logger.error(f"âŒ Workflow '{workflow_def.name}' failed: {str(e)}")
            logger.error(f"ğŸ” Traceback: {traceback.format_exc()}")
        
        finally:
            # Temizlik iÅŸlemleri
            if execution_id in self.active_executions:
                del self.active_executions[execution_id]
        
        return execution
    
    async def _execute_workflow_steps(self, workflow_def: WorkflowDefinition, execution: WorkflowExecution):
        """
        Ä°ÅŸ akÄ±ÅŸÄ± adÄ±mlarÄ±nÄ± sÄ±rayla veya paralel olarak Ã§alÄ±ÅŸtÄ±r.
        
        Args:
            workflow_def: Ä°ÅŸ akÄ±ÅŸÄ± tanÄ±mÄ±
            execution: Ã‡alÄ±ÅŸtÄ±rma durumu
        """
        
        # AdÄ±mlarÄ± baÄŸÄ±mlÄ±lÄ±k sÄ±rasÄ±na gÃ¶re grupla
        step_groups = self._organize_steps_by_dependencies(workflow_def.steps)
        
        # Her grup sÄ±rasÄ±yla, grup iÃ§indeki adÄ±mlar paralel Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r
        for group_index, step_group in enumerate(step_groups):
            logger.info(f"ğŸ”„ Executing step group {group_index + 1}/{len(step_groups)} with {len(step_group)} steps")
            
            # Grup iÃ§indeki adÄ±mlarÄ± paralel Ã§alÄ±ÅŸtÄ±r
            if workflow_def.parallel_execution and len(step_group) > 1:
                # Paralel Ã§alÄ±ÅŸtÄ±rma
                tasks = []
                for step in step_group:
                    task = asyncio.create_task(self._execute_single_step(step, execution))
                    tasks.append(task)
                
                # TÃ¼m adÄ±mlarÄ±n tamamlanmasÄ±nÄ± bekle
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # SonuÃ§larÄ± kontrol et
                for i, result in enumerate(results):
                    step = step_group[i]
                    if isinstance(result, Exception):
                        execution.failed_steps.append(step.step_id)
                        execution.error_messages.append(f"Step '{step.step_id}' failed: {str(result)}")
                        
                        if step.required and workflow_def.error_policy == "stop":
                            raise result
                    else:
                        execution.completed_steps.append(step.step_id)
            else:
                # SÄ±ralÄ± Ã§alÄ±ÅŸtÄ±rma
                for step in step_group:
                    try:
                        result = await self._execute_single_step(step, execution)
                        execution.completed_steps.append(step.step_id)
                        
                    except Exception as e:
                        execution.failed_steps.append(step.step_id)
                        execution.error_messages.append(f"Step '{step.step_id}' failed: {str(e)}")
                        
                        if step.required and workflow_def.error_policy == "stop":
                            raise e
    
    def _organize_steps_by_dependencies(self, steps: List[WorkflowStep]) -> List[List[WorkflowStep]]:
        """
        AdÄ±mlarÄ± baÄŸÄ±mlÄ±lÄ±k sÄ±rasÄ±na gÃ¶re gruplandÄ±r.
        Her grupta bulunan adÄ±mlar paralel Ã§alÄ±ÅŸtÄ±rÄ±labilir.
        
        Args:
            steps: Ä°ÅŸ akÄ±ÅŸÄ± adÄ±mlarÄ± listesi
            
        Returns:
            List[List[WorkflowStep]]: BaÄŸÄ±mlÄ±lÄ±k sÄ±rasÄ±na gÃ¶re gruplandÄ±rÄ±lmÄ±ÅŸ adÄ±mlar
        """
        
        # AdÄ±mlarÄ± ID'lerine gÃ¶re mapple
        step_map = {step.step_id: step for step in steps}
        
        # GruplarÄ± tutacak liste
        step_groups = []
        completed_steps = set()
        
        # TÃ¼m adÄ±mlar tamamlanana kadar devam et
        while len(completed_steps) < len(steps):
            # Bu iterasyonda Ã§alÄ±ÅŸtÄ±rÄ±labilecek adÄ±mlarÄ± bul
            ready_steps = []
            
            for step in steps:
                # Zaten tamamlanmÄ±ÅŸ adÄ±mlarÄ± atla
                if step.step_id in completed_steps:
                    continue
                
                # BaÄŸÄ±mlÄ±lÄ±klarÄ± kontrol et
                dependencies_met = all(dep in completed_steps for dep in step.dependencies)
                
                if dependencies_met:
                    ready_steps.append(step)
            
            # HazÄ±r adÄ±mlar yoksa sonsuz dÃ¶ngÃ¼ var demektir
            if not ready_steps:
                remaining_steps = [s.step_id for s in steps if s.step_id not in completed_steps]
                raise ValueError(f"Circular dependency detected in steps: {remaining_steps}")
            
            # HazÄ±r adÄ±mlarÄ± gruba ekle
            step_groups.append(ready_steps)
            
            # Bu adÄ±mlarÄ± tamamlanmÄ±ÅŸ olarak iÅŸaretle
            for step in ready_steps:
                completed_steps.add(step.step_id)
        
        return step_groups
    
    async def _execute_single_step(self, step: WorkflowStep, execution: WorkflowExecution) -> Dict[str, Any]:
        """
        Tek bir iÅŸ akÄ±ÅŸÄ± adÄ±mÄ±nÄ± Ã§alÄ±ÅŸtÄ±r.
        
        Args:
            step: Ã‡alÄ±ÅŸtÄ±rÄ±lacak adÄ±m
            execution: Ä°ÅŸ akÄ±ÅŸÄ± Ã§alÄ±ÅŸtÄ±rma durumu
            
        Returns:
            Dict[str, Any]: AdÄ±m sonucu
        """
        
        execution.current_step = step.step_id
        step_start_time = time.time()
        
        logger.info(f"ğŸ”„ Executing step '{step.step_id}' on service '{step.service_type.value}'")
        
        # Servis saÄŸlÄ±k durumunu kontrol et (Circuit Breaker Pattern)
        if not self.service_health.get(step.service_type, True):
            if step.fallback_enabled:
                logger.warning(f"âš ï¸ Service '{step.service_type.value}' is unhealthy, using fallback")
                return await self._execute_fallback_step(step, execution)
            else:
                raise Exception(f"Service '{step.service_type.value}' is unhealthy and no fallback available")
        
        # Retry mekanizmasÄ± ile adÄ±mÄ± Ã§alÄ±ÅŸtÄ±r
        last_exception = None
        for attempt in range(step.retry_count + 1):
            try:
                # Servis URL'sini oluÅŸtur
                service_url = self.service_urls[step.service_type]
                full_url = f"{service_url}{step.endpoint}"
                
                # Request payload'unu hazÄ±rla
                payload = self._prepare_step_payload(step, execution)
                
                # HTTP isteÄŸi gÃ¶nder
                async with aiohttp.ClientSession() as session:
                    async with session.post(
                        full_url,
                        json=payload,
                        timeout=aiohttp.ClientTimeout(total=step.timeout)
                    ) as response:
                        
                        if response.status == 200:
                            result = await response.json()
                            
                            # Sonucu execution context'e ekle
                            execution.context.step_results[step.step_id] = result
                            
                            # Performans metriklerini gÃ¼ncelle
                            step_duration = time.time() - step_start_time
                            execution.performance_metrics[f"{step.step_id}_duration"] = step_duration
                            
                            # Servis call count'Ä± artÄ±r
                            self.metrics["service_call_count"][step.service_type] += 1
                            
                            # Servis saÄŸlÄ±klÄ± olarak iÅŸaretle
                            self.service_health[step.service_type] = True
                            
                            logger.info(f"âœ… Step '{step.step_id}' completed in {step_duration:.2f}s")
                            return result
                        
                        else:
                            error_msg = f"HTTP {response.status}: {await response.text()}"
                            raise Exception(error_msg)
                
            except Exception as e:
                last_exception = e
                
                # Hata sayacÄ±nÄ± artÄ±r
                self.metrics["service_error_count"][step.service_type] += 1
                
                # Son deneme deÄŸilse retry yap
                if attempt < step.retry_count:
                    wait_time = 2 ** attempt  # Exponential backoff
                    logger.warning(f"âš ï¸ Step '{step.step_id}' attempt {attempt + 1} failed, retrying in {wait_time}s: {str(e)}")
                    await asyncio.sleep(wait_time)
                else:
                    # TÃ¼m denemeler baÅŸarÄ±sÄ±z
                    logger.error(f"âŒ Step '{step.step_id}' failed after {step.retry_count + 1} attempts: {str(e)}")
                    
                    # Servis saÄŸlÄ±ksÄ±z olarak iÅŸaretle
                    self.service_health[step.service_type] = False
                    
                    # Fallback varsa kullan
                    if step.fallback_enabled:
                        logger.info(f"ğŸ”„ Using fallback for step '{step.step_id}'")
                        return await self._execute_fallback_step(step, execution)
        
        # TÃ¼m denemeler ve fallback baÅŸarÄ±sÄ±z
        raise last_exception
    
    def _prepare_step_payload(self, step: WorkflowStep, execution: WorkflowExecution) -> Dict[str, Any]:
        """
        AdÄ±m iÃ§in HTTP request payload'unu hazÄ±rla.
        
        Args:
            step: Ã‡alÄ±ÅŸtÄ±rÄ±lacak adÄ±m
            execution: Ä°ÅŸ akÄ±ÅŸÄ± Ã§alÄ±ÅŸtÄ±rma durumu
            
        Returns:
            Dict[str, Any]: Request payload
        """
        
        # Base payload with context
        payload = {
            "user_id": execution.context.user_id,
            "session_id": execution.context.session_id,
            "workflow_id": execution.workflow_id,
            "execution_id": execution.execution_id,
            "step_id": step.step_id
        }
        
        # Input data'yÄ± ekle
        payload.update(execution.context.input_data)
        
        # Ã–nceki adÄ±mlarÄ±n sonuÃ§larÄ±nÄ± ekle
        payload["previous_results"] = execution.context.step_results
        
        # Context data'yÄ± ekle
        payload["context_data"] = execution.context.context_data
        
        return payload
    
    async def _execute_fallback_step(self, step: WorkflowStep, execution: WorkflowExecution) -> Dict[str, Any]:
        """
        AdÄ±m baÅŸarÄ±sÄ±z olduÄŸunda fallback mekanizmasÄ±nÄ± Ã§alÄ±ÅŸtÄ±r.
        
        Args:
            step: BaÅŸarÄ±sÄ±z olan adÄ±m
            execution: Ä°ÅŸ akÄ±ÅŸÄ± Ã§alÄ±ÅŸtÄ±rma durumu
            
        Returns:
            Dict[str, Any]: Fallback sonucu
        """
        
        logger.info(f"ğŸ”„ Executing fallback for step '{step.step_id}'")
        
        # Service type'a gÃ¶re basit fallback sonuÃ§larÄ± Ã¼ret
        fallback_results = {
            ServiceType.IMAGE_PROCESSING: {
                "status": "fallback",
                "analysis": {
                    "items_detected": ["generic_clothing_item"],
                    "colors": ["neutral"],
                    "style": "casual",
                    "confidence": 0.5
                },
                "message": "Using fallback image analysis due to service unavailability"
            },
            
            ServiceType.NLU: {
                "status": "fallback", 
                "analysis": {
                    "intent": "general_fashion_query",
                    "entities": ["clothing", "style"],
                    "sentiment": "neutral",
                    "confidence": 0.5
                },
                "message": "Using fallback text analysis due to service unavailability"
            },
            
            ServiceType.STYLE_PROFILE: {
                "status": "fallback",
                "style_profile": {
                    "style_category": "casual",
                    "preferences": ["comfortable", "versatile"],
                    "recommendations": "general_style_advice",
                    "confidence": 0.5
                },
                "message": "Using fallback style profiling due to service unavailability"
            },
            
            ServiceType.COMBINATION_ENGINE: {
                "status": "fallback",
                "combination": {
                    "items": ["basic_top", "basic_bottom"],
                    "style": "casual",
                    "occasion": "everyday",
                    "confidence": 0.5
                },
                "message": "Using fallback combination generation due to service unavailability"
            },
            
            ServiceType.RECOMMENDATION_ENGINE: {
                "status": "fallback",
                "recommendations": [
                    {"item": "versatile_piece_1", "score": 0.7, "reason": "fallback_recommendation"},
                    {"item": "versatile_piece_2", "score": 0.6, "reason": "fallback_recommendation"}
                ],
                "message": "Using fallback recommendations due to service unavailability"
            }
        }
        
        result = fallback_results.get(step.service_type, {
            "status": "fallback",
            "message": f"Generic fallback for {step.service_type.value}",
            "confidence": 0.3
        })
        
        # Sonucu execution context'e ekle
        execution.context.step_results[step.step_id] = result
        
        return result
    
    def _update_metrics(self, execution: WorkflowExecution, success: bool):
        """
        Ä°ÅŸ akÄ±ÅŸÄ± tamamlandÄ±ktan sonra metrikleri gÃ¼ncelle.
        
        Args:
            execution: Tamamlanan iÅŸ akÄ±ÅŸÄ± Ã§alÄ±ÅŸtÄ±rmasÄ±
            success: BaÅŸarÄ±lÄ± mÄ± baÅŸarÄ±sÄ±z mÄ±
        """
        
        self.metrics["total_workflows"] += 1
        
        if success:
            self.metrics["successful_workflows"] += 1
        else:
            self.metrics["failed_workflows"] += 1
        
        # Ortalama Ã§alÄ±ÅŸma sÃ¼resini gÃ¼ncelle
        duration = self._get_execution_duration(execution)
        current_avg = self.metrics["average_execution_time"]
        total_count = self.metrics["total_workflows"]
        
        self.metrics["average_execution_time"] = (
            (current_avg * (total_count - 1) + duration) / total_count
        )
    
    def _get_execution_duration(self, execution: WorkflowExecution) -> float:
        """
        Ä°ÅŸ akÄ±ÅŸÄ± Ã§alÄ±ÅŸma sÃ¼resini hesapla.
        
        Args:
            execution: Ä°ÅŸ akÄ±ÅŸÄ± Ã§alÄ±ÅŸtÄ±rmasÄ±
            
        Returns:
            float: SÃ¼re (saniye)
        """
        if execution.end_time:
            return (execution.end_time - execution.start_time).total_seconds()
        else:
            return (datetime.now() - execution.start_time).total_seconds()
    
    def get_workflow_status(self, execution_id: str) -> Optional[WorkflowExecution]:
        """
        Ã‡alÄ±ÅŸan bir iÅŸ akÄ±ÅŸÄ±nÄ±n durumunu getir.
        
        Args:
            execution_id: Ä°ÅŸ akÄ±ÅŸÄ± Ã§alÄ±ÅŸtÄ±rma kimliÄŸi
            
        Returns:
            Optional[WorkflowExecution]: Ä°ÅŸ akÄ±ÅŸÄ± durumu veya None
        """
        return self.active_executions.get(execution_id)
    
    def get_metrics(self) -> Dict[str, Any]:
        """
        OrkestratÃ¶r performans metriklerini getir.
        
        Returns:
            Dict[str, Any]: DetaylÄ± metrik bilgileri
        """
        return {
            "orchestrator_metrics": self.metrics.copy(),
            "service_health": self.service_health.copy(),
            "active_executions": len(self.active_executions),
            "available_workflows": list(self.workflow_definitions.keys())
        }
    
    def register_workflow(self, workflow_def: WorkflowDefinition):
        """
        Yeni bir iÅŸ akÄ±ÅŸÄ± tanÄ±mÄ± kaydet.
        
        Args:
            workflow_def: Ä°ÅŸ akÄ±ÅŸÄ± tanÄ±mÄ±
        """
        self.workflow_definitions[workflow_def.workflow_id] = workflow_def
        logger.info(f"âœ… Registered workflow '{workflow_def.name}' (ID: {workflow_def.workflow_id})")
    
    async def cancel_workflow(self, execution_id: str) -> bool:
        """
        Ã‡alÄ±ÅŸan bir iÅŸ akÄ±ÅŸÄ±nÄ± iptal et.
        
        Args:
            execution_id: Ä°ptal edilecek iÅŸ akÄ±ÅŸÄ± kimliÄŸi
            
        Returns:
            bool: Ä°ptal baÅŸarÄ±lÄ± mÄ±
        """
        if execution_id in self.active_executions:
            execution = self.active_executions[execution_id]
            execution.status = WorkflowStatus.CANCELLED
            execution.end_time = datetime.now()
            
            # Aktif listeden Ã§Ä±kar
            del self.active_executions[execution_id]
            
            logger.info(f"ğŸš« Workflow {execution_id} cancelled successfully")
            return True
        
        return False

# Global orchestrator instance - singleton pattern
aura_orchestrator = AuraWorkflowOrchestrator()

# Kolay kullanÄ±m iÃ§in helper fonksiyonlar
async def execute_complete_fashion_analysis(user_id: str, image_data: Any, text_query: str) -> WorkflowExecution:
    """
    Tam moda analizi iÅŸ akÄ±ÅŸÄ±nÄ± Ã§alÄ±ÅŸtÄ±r.
    
    Args:
        user_id: KullanÄ±cÄ± kimliÄŸi
        image_data: GÃ¶rÃ¼ntÃ¼ verisi
        text_query: Metin sorgusu
        
    Returns:
        WorkflowExecution: Ä°ÅŸ akÄ±ÅŸÄ± sonucu
    """
    context = WorkflowContext(
        user_id=user_id,
        session_id=str(uuid.uuid4()),
        input_data={
            "image": image_data,
            "text": text_query,
            "analysis_type": "comprehensive"
        }
    )
    
    return await aura_orchestrator.execute_workflow("complete_fashion_analysis", context)

async def execute_quick_style_assessment(user_id: str, image_data: Any) -> WorkflowExecution:
    """
    HÄ±zlÄ± stil deÄŸerlendirmesi iÅŸ akÄ±ÅŸÄ±nÄ± Ã§alÄ±ÅŸtÄ±r.
    
    Args:
        user_id: KullanÄ±cÄ± kimliÄŸi
        image_data: GÃ¶rÃ¼ntÃ¼ verisi
        
    Returns:
        WorkflowExecution: Ä°ÅŸ akÄ±ÅŸÄ± sonucu
    """
    context = WorkflowContext(
        user_id=user_id,
        session_id=str(uuid.uuid4()),
        input_data={
            "image": image_data,
            "analysis_type": "quick"
        }
    )
    
    return await aura_orchestrator.execute_workflow("quick_style_assessment", context)

# Test fonksiyonu
async def test_orchestrator():
    """
    Orchestrator'Ä±n temel iÅŸlevlerini test et.
    """
    logger.info("ğŸ§ª Testing Aura Workflow Orchestrator...")
    
    # Test context'i oluÅŸtur
    test_context = WorkflowContext(
        user_id="test_user_123",
        session_id="test_session_456",
        input_data={
            "text": "I need a casual outfit for weekend",
            "image": "test_image_data",
            "analysis_type": "comprehensive"
        }
    )
    
    # Test iÅŸ akÄ±ÅŸÄ±nÄ± Ã§alÄ±ÅŸtÄ±r
    try:
        result = await aura_orchestrator.execute_workflow("complete_fashion_analysis", test_context)
        logger.info(f"âœ… Test workflow completed with status: {result.status}")
        logger.info(f"ğŸ“Š Execution took {aura_orchestrator._get_execution_duration(result):.2f} seconds")
        
        # Metrikleri gÃ¶ster
        metrics = aura_orchestrator.get_metrics()
        logger.info(f"ğŸ“ˆ Orchestrator metrics: {metrics}")
        
    except Exception as e:
        logger.error(f"âŒ Test workflow failed: {str(e)}")

if __name__ == "__main__":
    # Test Ã§alÄ±ÅŸtÄ±r
    asyncio.run(test_orchestrator())
